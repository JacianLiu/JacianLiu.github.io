{"pages":[{"title":"归档","text":"","link":"/archives/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"友情链接","text":"","link":"/links/index.html"},{"title":"联系我","text":"Email：JacianLiu@gmail.comTelegram: https://t.me/Jacian_6GitHub: https://github.com/JacianLiu","link":"/contact/index.html"},{"title":"标签","text":"","link":"/tags/index.html"},{"title":"Repositories","text":"","link":"/repository/index.html"}],"posts":[{"title":"一文详解Spring循环依赖","text":"什么是循环依赖？大家都知道spring的核心是一个实现了AOP的IOC容器，那么IOC容器对于bean的初始化，会遇到以下情况：当BeanA初始化时，它依赖的对象BeanB也需要执行初始化，如果BeanB里也依赖了BeanA,则又会开始执行BeanA的初始化，那么这样会无限循环，导致初始化异常如下所示。Spring已经很好的解决了这个问题，这个解决方法就是三级缓存。什么是三级缓存？我们以上图中A、B互相依赖为例，spring为了解决循环依赖问题，做了以下步骤：A通过反射创建的“初级bean”a放入到三级缓存中，再执行a的属性填充，这时发现依赖B，开启B的初始化。B通过反射生成的“初级bean”b放入到三级缓存中，再执行b的属性填充，这时发现依赖A，开启A的初始化。从三级缓存中找到a，A不再创建新对象，把它移动到二级缓存中，返回a。b拿到a的引用，设置到b对应的字段上，属性填充完成，将b从三级缓存暴露到一级缓存中，返回b。a拿到b的引用，设置到a对应的字段上，属性填充完成，将a从二级缓存暴露到一级缓存中，返回a，A对应的实例Bean初始化完成。其简易时序图：逻辑图如下：咱们再看看三级缓存的存储结构：123456789101112/** Cache of singleton objects: bean name to bean instance. */ /** 一级缓存，初始化完成的SpringBean均放置其中 */ private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); /** Cache of early singleton objects: bean name to bean instance. */ /** 二级缓存，反射完成后，还未填充属性的初级对象但是其他对象查询过时从三级中移动到二级 */ private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);/** Cache of singleton factories: bean name to ObjectFactory. */ /** 三级缓存，反射完成后，还未填充属性的初级对象放置其中 */ private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);1234567891011为什么三级缓存earlySingletonObjects和二级缓存singletonFactories的初始容量16，而一级缓存容量为256呢？笔者认为因为二级、三级仅仅是在处理依赖时会使用到，这种多重循环依赖的情况在实际项目中应该是少数，所以不用使用太大的空间。而最终spring实例化完成的bean会放置在一级缓存中，所以默认容量会调大一些，毕竟spring有很多自身的bean也是放置在这里面的，比如systemEnvironment、systemProperties、messageSource、applicationEventMulticaster等。spring的源码阅读当单例对象不存在时，会通过org.springframework.beans.factory.support.DefaultSingletonBeanRegistry#getSingleton(java.lang.String, org.springframework.beans.factory.ObjectFactory&lt;?&gt;)方法来获取单例对象。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) { /** 省略部分代码 */ synchronized (this.singletonObjects) { Object singletonObject = this.singletonObjects.get(beanName); // 在一级缓存singletonObjects中拿到为空 if (singletonObject == null) { /** 省略状态检查部分代码 */ boolean newSingleton = false; try { // 传进来的调用，lamda表达式使用 singletonObject = singletonFactory.getObject(); // *********重要*********：singletonFactory.getObject()执行完毕，标记此类已经初始化完成 // bean初始化完成，标记为新的单例对象 newSingleton = true; } catch (IllegalStateException ex) { /** 省略部分代码 */ } finally { if (recordSuppressedExceptions) { this.suppressedExceptions = null; } afterSingletonCreation(beanName); } // 如果是新的单例对象，暴露到一级缓存中 if (newSingleton) { addSingleton(beanName, singletonObject); } } return singletonObject; } } /** * Add the given singleton object to the singleton cache of this factory. * &lt;p&gt;To be called for eager registration of singletons. * @param beanName the name of the bean * @param singletonObject the singleton object */ protected void addSingleton(String beanName, Object singletonObject) { synchronized (this.singletonObjects) { // 加入到一级缓存，从二级和三级缓存中移除; this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); } }上面代码中的singletonFactory.getObject() 无疑是执行创建的关键代码：org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#createBean(java.lang.String, org.springframework.beans.factory.support.RootBeanDefinition, java.lang.Object[])方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Central method of this class: creates a bean instance, * populates the bean instance, applies post-processors, etc. * @see #doCreateBean */ @Override protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException { // 拿到Bd RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. // 获得类信息 Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) { mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); } // Prepare method overrides. try { // 检查该bean是否有重载方法 mbdToUse.prepareMethodOverrides(); } catch (BeanDefinitionValidationException ex) { /** 省略部分代码 */ } try { // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. Object bean = resolveBeforeInstantiation(beanName, mbdToUse); // 尝试获取代理对象; if (bean != null) { return bean; } } catch (Throwable ex) { /** 省略部分代码 */ } try { // 进入，真真正正创建bean Object beanInstance = doCreateBean(beanName, mbdToUse, args); return beanInstance; } catch (Throwable ex) { /** 省略部分代码 */ } }再来看看doCreateBean方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/** * Actually create the specified bean. Pre-creation processing has already happened * at this point, e.g. checking {@code postProcessBeforeInstantiation} callbacks. * &lt;p&gt;Differentiates between default bean instantiation, use of a * factory method, and autowiring a constructor. * @param beanName the name of the bean * @param mbd the merged bean definition for the bean * @param args explicit arguments to use for constructor or factory method invocation * @return a new instance of the bean * @throws BeanCreationException if the bean could not be created * @see #instantiateBean * @see #instantiateUsingFactoryMethod * @see #autowireConstructor */ protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException { BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) { instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); } if (instanceWrapper == null) { // 创建 Bean 实例，仅仅调用构造方法，但是尚未设置属性 instanceWrapper = createBeanInstance(beanName, mbd, args); } final Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) { mbd.resolvedTargetType = beanType; } /** 省略部分代码 */ // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) { // 暴露到三级缓存中 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); } // 初始化bean实例 Object exposedObject = bean; try { // Bean属性填充 populateBean(beanName, mbd, instanceWrapper); // 调用初始化方法，应用BeanPostProcessor后置处理器 exposedObject = initializeBean(beanName, exposedObject, mbd); } catch (Throwable ex) { /** 省略部分代码 */ } if (earlySingletonExposure) { // 调用一次getSingleton(beanName, false)方法-&gt;\" + beanName)，只从一级、二级缓存中拿，传入false不需要从三级添加到二级缓存; // 核心逻辑是：如果提前暴露到了二级，则返回二级缓存中的对象引用，此时可能获取得到的是原对象的代理对象。因为AOP动态代理时，会将对象提升二级缓存，本文不再详述此问题 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) { if (exposedObject == bean) { exposedObject = earlySingletonReference; } else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) { /** 省略部分代码,检查依赖对象是否均创建完成 */ } } } // Register bean as disposable. try { // 初始化完成后一些注册操作 registerDisposableBeanIfNecessary(beanName, bean, mbd); } catch (BeanDefinitionValidationException ex) { /** 省略部分代码 */ } return exposedObject; }从doCreateBean方法可以看出：先调用构造方法，生成初级bean，然后暴露到三级缓存，然后执行属性填充，最表标记bean初始化完成，如果二级缓存有，则替换引用，最后完成注册并返回对象。那么这个填充属性方法populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) 又做了什么呢？12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) { /** 省略部分代码 */ PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); int resolvedAutowireMode = mbd.getResolvedAutowireMode(); if (resolvedAutowireMode == AUTOWIRE_BY_NAME || resolvedAutowireMode == AUTOWIRE_BY_TYPE) { MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. if (resolvedAutowireMode == AUTOWIRE_BY_NAME) { autowireByName(beanName, mbd, bw, newPvs); } // Add property values based on autowire by type if applicable. if (resolvedAutowireMode == AUTOWIRE_BY_TYPE) { autowireByType(beanName, mbd, bw, newPvs); } pvs = newPvs; } boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE); PropertyDescriptor[] filteredPds = null; if (hasInstAwareBpps) { if (pvs == null) { pvs = mbd.getPropertyValues(); } for (BeanPostProcessor bp : getBeanPostProcessors()) { if (bp instanceof InstantiationAwareBeanPostProcessor) { InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); if (pvsToUse == null) { if (filteredPds == null) { filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); } pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvsToUse == null) { return; } } pvs = pvsToUse; } } } if (needsDepCheck) { if (filteredPds == null) { filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); } checkDependencies(beanName, mbd, filteredPds, pvs); } if (pvs != null) { applyPropertyValues(beanName, mbd, bw, pvs); } }代码比较多，核心思想就是获取这个bean里的所有依赖bean，然后调用applyPropertyValues方法去创建对应的依赖bean，并设置到对应的属性上。12345678910111213141516171819202122232425protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) { /** 省略部分代码 */ BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter); // Create a deep copy, resolving any references for values. List&lt;PropertyValue&gt; deepCopy = new ArrayList&lt;&gt;(original.size()); boolean resolveNecessary = false; for (PropertyValue pv : original) { if (pv.isConverted()) { deepCopy.add(pv); } else { String propertyName = pv.getName(); Object originalValue = pv.getValue(); // *** 将依赖的属性目标，转化为初始化完成后的bean Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); Object convertedValue = resolvedValue; /** 省略部分代码 */ pv.setConvertedValue(convertedValue); deepCopy.add(pv); /** 省略部分代码 */ } } /** 省略部分代码 */ }valueResolver.resolveValueIfNecessary方法经过一些的方法，最终调用beanFactory.getBean，这个方法会回到开始进行新一轮的创建bean12345678910private Object resolveInnerBean(Object argName, String innerBeanName, BeanDefinition innerBd) { String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) { for (String dependsOnBean : dependsOn) { this.beanFactory.registerDependentBean(dependsOnBean, actualInnerBeanName); // 初始化bean this.beanFactory.getBean(dependsOnBean); } }}allowEarlyReference传入true，对于新的bean，已经在三级缓存中存在，会将三级缓存转移到二级缓存，并返回bean，不用真正的去创建一个bean。1234567891011121314151617181920212223242526protected Object getSingleton(String beanName, boolean allowEarlyReference) { boolean needWarn = true; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) { synchronized (this.singletonObjects) { logger.warn(\"当前bean已注册，从一级earlySingletonObjects中拿不到-&gt;\" + beanName + \"：\" + singletonObject); singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) { logger.warn(\"当前bean已注册，从二级缓存earlySingletonObjects中拿不到-&gt;\" + beanName + \"：\" + singletonObject); ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) { singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); needWarn = false; logger.warn(\"当前bean已注册，从三级singletonFactories中拿到，并移动到二级缓存earlySingletonObjects-&gt;\" + beanName + \" ： \" + singletonObject); } } } } if (needWarn) { logger.warn(\"从三级缓存中查询，调用DefaultSingletonBeanRegistry.getSingleton(beanName, allowEarlyReference)-&gt;得到\" + beanName + \":\" + singletonObject + \" ,allowEarlyReference：\" + allowEarlyReference); } return singletonObject; }所以第三步的Bean B属性填充方法此时完成，Bean B被加载到一级缓存中。由此回溯，Bean A的属性填充完成，Bean A被加载到一级缓存中。可结合本文最开始给出的时序图进行参考。其他问题为什么要用三级缓存而不是二级?我们可以从三级缓存的值类型看出，一、二级的值均为Spring Bean对象的引用，三级对象则为ObjectFactory的引用。1234567891011/** Cache of singleton objects: bean name to bean instance. */ /** 一级缓存，初始化完成的SpringBean均放置其中 */ private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); /** Cache of early singleton objects: bean name to bean instance. */ /** 二级缓存，反射完成后，还未填充属性的初级对象但是其他对象查询过时从三级中移动到二级 */ private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);/** Cache of singleton factories: bean name to ObjectFactory. */ /** 三级缓存，反射完成后，还未填充属性的初级对象放置其中 */ private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);为什么要有ObjectFactory类型的第三级缓存？将对象从三级缓存singletonFactories中移动到二级缓存时，会执行ObjectFactory的getBean方法，再调用到getEarlyBeanReference方法，最终遍历该Bean对应的所有SmartInstantiationAwareBeanPostProcessor进行执行；熟悉spring的朋友们肯定知道，SmartInstantiationAwareBeanPostProcessor是Spring Aop动态代理相关属性处理器。执行后获得一个新的bean，该bean是原bean代理对象。1234567891011121314151617181920212223// 新生成一个Factory对象，并设置其getBean方法为getEarlyBeanReferenceaddSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));// 等价于以下代码/* addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() { @Override public Object getObject() throws BeansException { return getEarlyBeanReference(beanName, mbd, bean); } }); */123456789// getEarlyBeanReference方法：将会遍历其所有的SmartInstantiationAwareBeanPostProcessor（智能化属性处理器，然后进行执行）protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) { Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) { for (BeanPostProcessor bp : getBeanPostProcessors()) { if (bp instanceof SmartInstantiationAwareBeanPostProcessor) { SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); } } } return exposedObject; }也就是说，三级缓存 存在的目的就是增强对象，当需要使用spring的aop功能时返回代理对象，如果咱们永远用不到代理对象，三级缓存理论上可以不用。既然三级缓存为了获取代理对象，只保留一三级缓存、第二级缓存可以不要吗？理论上可以，只需要两级缓存就可以解决循环依赖的问题，但在处理循环依赖的过程，一级缓存中将可能同时存在完整Spring Bean A 和 半成品Spring Bean B。三级对象getObject之后直接放置到二级，最后再刷到一级，二级到一级这个过程中并无额外的处理。那么为什么spring要使用三级呢？笔者认为一是为了规范各级缓存职责单一原则，不让一级缓存中出现完整的bean和半成品bean；二是为了避免半成品bean被其他线程获取后进行调用，降低实现的难度。文章转自：https://blog.csdn.net/ksisn/article/details/110730050文章转自：https://blog.csdn.net/ksisn/article/details/110730050文章转自：https://blog.csdn.net/ksisn/article/details/110730050","link":"/2020/12/1608133537885/"},{"title":"IOC容器加载流程","text":"Spring容器的AbstractApplicationContext#refresh()【容器刷新】源码解析；本文只记录大体步骤， 细节部分自行阅读源码；AbstractApplicationContext#refresh()是IOC容器加载的主要流程，源代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110@Override public void refresh() throws BeansException, IllegalStateException { // 对象锁加锁 synchronized (this.startupShutdownMonitor) { /* Prepare this context for refreshing. 刷新前的预处理 表示在真正做refresh操作之前需要准备做的事情： 设置Spring容器的启动时间， 开启活跃状态，撤销关闭状态 验证环境信息里一些必须存在的属性等 */ prepareRefresh(); /* Tell the subclass to refresh the internal bean factory. 获取BeanFactory；默认实现是DefaultListableBeanFactory 加载BeanDefition 并注册到 BeanDefitionRegistry */ ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); /* Prepare the bean factory for use in this context. BeanFactory的预准备工作（BeanFactory进行一些设置，比如context的类加载器等） */ prepareBeanFactory(beanFactory); try { /* Allows post-processing of the bean factory in context subclasses. BeanFactory准备工作完成后进行的后置处理工作 */ postProcessBeanFactory(beanFactory); /* Invoke factory processors registered as beans in the context. 实例化实现了BeanFactoryPostProcessor接口的Bean，并调用接口方法 */ invokeBeanFactoryPostProcessors(beanFactory); /* Register bean processors that intercept bean creation. 注册BeanPostProcessor（Bean的后置处理器），在创建bean的前后等执行 */ registerBeanPostProcessors(beanFactory); /* Initialize message source for this context. 初始化MessageSource组件（做国际化功能；消息绑定，消息解析）； */ initMessageSource(); /* Initialize event multicaster for this context. 初始化事件派发器 */ initApplicationEventMulticaster(); /* Initialize other special beans in specific context subclasses. 子类重写这个方法，在容器刷新的时候可以自定义逻辑；如创建Tomcat，Jetty等WEB服务器 */ onRefresh(); /* Check for listener beans and register them. 注册应用的监听器。就是注册实现了ApplicationListener接口的监听器bean */ registerListeners(); /* Instantiate all remaining (non-lazy-init) singletons. 初始化所有剩下的非懒加载的单例bean 初始化创建非懒加载方式的单例Bean实例（未设置属性） 填充属性 初始化方法调用（比如调用afterPropertiesSet方法、init-method方法） 调用BeanPostProcessor（后置处理器）对实例bean进行后置处理 */ finishBeanFactoryInitialization(beanFactory); /* Last step: publish corresponding event. 完成context的刷新。主要是调用LifecycleProcessor的onRefresh()方法，并且发布事件（ContextRefreshedEvent） */ finishRefresh(); } catch (BeansException ex) { if (logger.isWarnEnabled()) { logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); } // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; } finally { // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); } } }逐步剖析prepareRefresh();刷新前的预处理，在这里主要完成对Spring的启动时间进行记录、对系统变量的属性合法性进行校验、初始化容器事件列表1234567891011121314151617181920212223242526272829303132333435protected void prepareRefresh() { // Switch to active. // 启动日期startupDate和活动标志active this.startupDate = System.currentTimeMillis(); this.closed.set(false); this.active.set(true); if (logger.isDebugEnabled()) { if (logger.isTraceEnabled()) { logger.trace(\"Refreshing \" + this); } else { logger.debug(\"Refreshing \" + getDisplayName()); } } // 初始化属性设置，默认实现为空 initPropertySources(); // 属性合法性校验 getEnvironment().validateRequiredProperties(); // 事件存储容器 if (this.earlyApplicationListeners == null) { this.earlyApplicationListeners = new LinkedHashSet&lt;&gt;(this.applicationListeners); } else { // 重置事件存储容器 this.applicationListeners.clear(); this.applicationListeners.addAll(this.earlyApplicationListeners); } // 存储容器中早期事件的容器，在多播器可用时进行发布 this.earlyApplicationEvents = new LinkedHashSet&lt;&gt;(); }obtainFreshBeanFactory();初始化BeanFactory；这一步主要完成了BeanFactory的创建以及获取；123456789101112131415161718192021222324252627282930313233343536protected ConfigurableListableBeanFactory obtainFreshBeanFactory() { refreshBeanFactory(); return getBeanFactory();}@Overrideprotected final void refreshBeanFactory() throws BeansException { // 判断是否已有bean factory if (hasBeanFactory()) { // 销毁 beans destroyBeans(); // 关闭 bean factory closeBeanFactory(); } try { // 实例化 DefaultListableBeanFactory DefaultListableBeanFactory beanFactory = createBeanFactory(); // 设置序列化id beanFactory.setSerializationId(getId()); // 自定义bean工厂的一些属性（是否覆盖、是否允许循环依赖） customizeBeanFactory(beanFactory); // 解析XML配置文件，加载应用中的BeanDefinitions loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) { // 赋值当前bean facotry this.beanFactory = beanFactory; } } catch (IOException ex) { throw new ApplicationContextException(\"I/O error parsing bean definition source for \" + getDisplayName(), ex); }} protected DefaultListableBeanFactory createBeanFactory() { return new DefaultListableBeanFactory(getInternalParentBeanFactory());}在源码中可以获得以下三个重要信息：调用refreshBeanFactory()方法创建了BeanFactory，它的默认实现是DefaultListableBeanFactory()调用了loadBeanDefinitions()方法，完成了配置文件的解析，并封装成了BeanDefinitions对象存储到BeanFactory中；getBeanFactory();获取创建好的BeanFactory并返回prepareBeanFactory(beanFactory);BeanFactory的预准备工作，对BeanFactory进行一些默认设置；12345678910111213141516171819202122232425262728293031323334353637383940414243protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) { // 上下文以及类加载器设置 beanFactory.setBeanClassLoader(getClassLoader()); beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // 配置BeanFactory的上下文回调 beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); // 设置忽略的自动装配接口，如：EnvironmentAware、EmbeddedValueResolverAware、ResourceLoaderAware等。 beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); // 注册可以解析的自动装配，可以直接在其它组件中自动注入，如：BeanFactory、ResourceLoaderAware、ApplicationEventPublisher、ApplicationContext。 beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // 添加BeanPostProcessor——ApplicationListenerDetector beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); // Detect a LoadTimeWeaver and prepare for weaving, if found. if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) { beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); // Set a temporary ClassLoader for type matching. beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); } // 添加常用系统组件 if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) { beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); } if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) { beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); } if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) { beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); }}BeanFactory的一些必要配置，不赘述。postProcessBeanFactory(beanFactory);BeanFactory准备工作完成后进行的后置处理工作，Spring预留的切入点，子类通过重写这个方法，在BeanFactory创建并预准备完成后做进一步的操作。invokeBeanFactoryPostProcessors(beanFactory);执行BeanFactoryPostProcessor，BeanFactoryPostProcessor是BeanFactory的后置处理器，执行时机是BeanFactory标准初始化之后执行的，涉及接口：BeanFactoryPostProcessor、BeanDefinitionRegistryPostProcessor等。123456789101112protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) { // 执行后置处理器（内部代码太长，不贴了，自行看），获取到所有的BeanFactoryPostProcessor // 排序后依次执行（排序方式按照：实现PriorityOrdered、实现Ordered接口、未实现优先级接口） PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); // Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime // (e.g. through an @Bean method registered by ConfigurationClassPostProcessor) if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) { beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); }}这部分主要就是执行容器中BeanFactoryPostProcessor 的子类，对其子类注入BeanFactory，拆分一下执行流程大概分为以下四步：获取所有BeanDefinitionRegistryPostProcessor按照优先级进行排序，并按照优先级顺序执行BeanDefinitionRegistryPostProcessor#postProcessBeanDefinitionRegistry(registry);，优先级顺序按照：实现PriorityOrdered、实现Ordered接口、未实现优先级接口获取所有BeanFactoryPostProcessor按照优先级进行排序，并按照先后顺序执行BeanFactoryPostProcessor#postProcessBeanFactory(beanFactory);，优先级顺序按照：实现PriorityOrdered、实现Ordered接口、未实现优先级接口registerBeanPostProcessors(beanFactory);注册BeanPostProcessor，BeanPostProcessor是Bean的后置处理器，用于拦截Bean 的创建过程，以下为内置的一些BeanPostProcessor：BeanPostProcessor DestructionAwareBeanPostProcessor InstantiationAwareBeanPostProcessor SmartInstantiationAwareBeanPostProcessor MergedBeanDefinitionPostProcessor12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273protected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) { PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);}public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) { // 获取所有类型为 BeanPostProcessor 的BeanName String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // Register BeanPostProcessorChecker that logs an info message when // a bean is created during BeanPostProcessor instantiation, i.e. when // a bean is not eligible for getting processed by all BeanPostProcessors. int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // 按照实现PriorityOrdered接口，Ordered接口和未实现优先级接口的顺序排序BeanPostProcessor List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) { if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } else if (beanFactory.isTypeMatch(ppName, Ordered.class)) { orderedPostProcessorNames.add(ppName); } else { nonOrderedPostProcessorNames.add(ppName); } } // 首先注册实现PriorityOrdered接口的后置处理器 sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // 然后注册实现 Ordered 接口的后置处理器 List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : orderedPostProcessorNames) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // 最后注册没有实现优先级接口的后置处理器 List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : nonOrderedPostProcessorNames) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // 最后注册 MergedBeanDefinitionPostProcessor sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); // 最后在BeanPostProcessor的链尾再加入ApplicationListenerDetector // ApplicationListenerDetector作用功能是用于检测容器中的ApplicationLisenter，将其注册到上下文中 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));}上边代码比较长，其实做的事并没有这么复杂，主要就是对容器中后置处理器的排序，然后遍历注册的过程：获取所有BeanPostProcessor，不同接口类型的BeanPostProcessor，执行时机不同；【后置处理器都可以通过PriorityOrdered、Ordered指定优先级】按照优先级进行排序，并按照先后顺序注册（beanFactory#addBeanPostProcessor(postProcessor);），优先级顺序：实现PriorityOrdered、实现Ordered接口、未实现优先级接口最后注册MergedBeanDefinitionPostProcessor类型的后置处理器最终注册负责扫描发现监听器子类的处理器ApplicationListenerDetector，在Bean创建完成后，检查是不是ApplicationListener类型，如果是就注册到容器中initMessageSource();初始化MessageSource组件（国际化、消息绑定、消息解析）1234567891011121314151617181920212223242526272829303132protected void initMessageSource() { ConfigurableListableBeanFactory beanFactory = getBeanFactory(); // MESSAGE_SOURCE_BEAN_NAME = \"messageSource\"，尝试在BeanFactory中获取ID为messageSource // 并且类型为MessageSource的Bean，如果有直接赋值 if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) { this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class); // Make MessageSource aware of parent MessageSource. if (this.parent != null &amp;&amp; this.messageSource instanceof HierarchicalMessageSource) { HierarchicalMessageSource hms = (HierarchicalMessageSource) this.messageSource; if (hms.getParentMessageSource() == null) { // Only set parent context as parent MessageSource if no parent MessageSource // registered already. hms.setParentMessageSource(getInternalParentMessageSource()); } } if (logger.isTraceEnabled()) { logger.trace(\"Using MessageSource [\" + this.messageSource + \"]\"); } } // 如果没有就直接赋值类型为DelegatingMessageSource的实例 else { // Use empty MessageSource to be able to accept getMessage calls. DelegatingMessageSource dms = new DelegatingMessageSource(); dms.setParentMessageSource(getInternalParentMessageSource()); this.messageSource = dms; beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource); if (logger.isTraceEnabled()) { logger.trace(\"No '\" + MESSAGE_SOURCE_BEAN_NAME + \"' bean, using [\" + this.messageSource + \"]\"); } }}在这一步可以看出，如果我们需要使用国际化组件，只需要把MessageSource注册到容器中，获取国际化配置文件时，可以注入MessageSource组件进行使用：尝试在BeanFactory中获取id为messageSource且类型为MessageSource的组件如果有就拿过来直接赋值；如果没有就自己创建一个DelegatingMessageSource；initApplicationEventMulticaster();初始化事件派发器12345678910111213141516171819202122protected void initApplicationEventMulticaster() { ConfigurableListableBeanFactory beanFactory = getBeanFactory(); // APPLICATION_EVENT_MULTICASTER_BEAN_NAME = \"applicationEventMulticaster\" // 尝试在容器中获取ID为applicationEventMulticaster并且类型为ApplicationEventMulticaster的Bean // 如果有直接赋值 if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) { this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); if (logger.isTraceEnabled()) { logger.trace(\"Using ApplicationEventMulticaster [\" + this.applicationEventMulticaster + \"]\"); } } // 如果没有，那么构建一个SimpleApplicationEventMulticaster实例注册到容器中 else { this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); if (logger.isTraceEnabled()) { logger.trace(\"No '\" + APPLICATION_EVENT_MULTICASTER_BEAN_NAME + \"' bean, using \" + \"[\" + this.applicationEventMulticaster.getClass().getSimpleName() + \"]\"); } }}这一步和国际化组件的初始化流程类型，可以我们自身指定它的实现，如果不指定也没关系，因为Spring会有自身默认的实现尝试在BeanFactory中获取id为applicationEventMulticaster且类型为ApplicationEventMulticaster的组件；如果有则直接赋值到applicationEventMulticaster如果未找到applicationEventMulticaster组件，则会自动创建一个SimpleApplicationEventMulticaster的事件派发器，并将其添加到添加到容器中onRefresh();容器初始化期间执行的操作，子类重写这个方法，在容器刷新的时候可以自定义逻辑；如创建Tomcat，Jetty等WEB服务器registerListeners();将所有事件监听器注册到容器中，也就是注册实现了ApplicationListener的Bean123456789101112131415161718192021protected void registerListeners() { // 获取预先存放的事件监听器 for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) { getApplicationEventMulticaster().addApplicationListener(listener); } // 获取容器中所有类型为ApplicationListener 的Bean，注册到容器中 String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) { getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); } // 派发之前产生的事件 Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; if (earlyEventsToProcess != null) { for (ApplicationEvent earlyEvent : earlyEventsToProcess) { getApplicationEventMulticaster().multicastEvent(earlyEvent); } }}总结下来其实也就是以下三个步骤：拿到容器中所有ApplicationListener将每个事件监听器添加到事件派发器中派发之前产生的事件finishBeanFactoryInitialization(beanFactory);初始化所有剩下的单实例Bean，其中调用的beanFactory.preInstantiateSingletons();方法用于实现初始化其余单实例Bean的逻辑获取容器中所有的Bean，依次进行初始化和创建对象RootBeanDefinition依次获取Bean的定义信息判断Bean：不是抽象的 &amp;&amp; 是单实例的 &amp;&amp; 不是懒加载的判断是否是FactoryBean：是否是实现了FactoryBean接口。如果是则调用getObject();获取对象；如果不是FactoryBean，利用getBean(beanName);创建对象先获取缓存中保存的单实例Bean，如果能获取到说明之前已经创建过（所有创建的Bean都会被缓存起来）Map singletonObjects = new ConcurrentHashMap(256);如果缓存中获取不到Bean，开始创建Bean流程标记当前Bean已经被创建【markBeanAsCreated(beanName);】获取Bean定义信息【final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);】【获取当前Bean依赖的其它Bean（String[] dependsOn = mbd.getDependsOn();）。如果有，按照getBean()方式，把依赖的Bean先创建出来】启动单实例Bean创建流程（createBean(beanName, mbd, args);）resolveBeforeInstantiation(beanName, mbdToUse);让BeanPostProcessor先拦截返回代理对象；如果是InstantiationAwareBeanPostProcessor类型，则执行postProcessBeforeInstantiation方法，如果有返回值，再触发postProcessAfterInitialization方法如果前边的InstantiationAwareBeanPostProcessor没有返回代理对象，则执行3，如果返回了代理对象则直接返回Bean执行Object beanInstance = doCreateBean(beanName, mbdToUse, args);创建Bean【创建Bean实例】createBeanInstance(beanName, mbd, args);，利用工厂方法或对象构造器创建Bean实例applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);，调用MergedBeanDefinitionPostProcessor#postProcessMergedBeanDefinition方法【Bean属性赋值】populateBean(beanName, mbd, instanceWrapper);执行InstantiationAwareBeanPostProcessor后置处理器的postProcessAfterInstantiation方法执行InstantiationAwareBeanPostProcessor后置处理器的postProcessPropertyValues方法applyPropertyValues(beanName, mbd, bw, pvs);应用Bean的属性值，为属性利用getset方法等进行赋值【Bean初始化】initializeBean(beanName, exposedObject, mbd);【执行Aware】invokeAwareMethods(beanName, bean);执行xxxAwaer接口方法；如：BeanNameAware、BeanClassLoaderAware、BeanFactoryAware【执行后置处理器初始化之前的方法】applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); ，执行BeanPostProcessor#postProcessBeforeInitialization方法【执行Bean初始化方法】invokeInitMethods(beanName, wrappedBean, mbd);判断是不是实现了InitializingBean接口，如果是执行该接口规定的初始化方法判断是不是自定义了初始化方法【执行初后置处理器初始化之后方法】applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);，执行BeanPostProcessor#postProcessAfterInitialization方法【注册Bean销毁方法】registerDisposableBeanIfNecessary(beanName, bean, mbd);将创建的Bean存入缓存：singletonObjects，IOC就是Map，很多的Map保存了单实例Bean、环境信息等。。。所有Bean都利用getBean()创建完成之后，检查所有的Bean是否实现了SmartInitializingSingleton接口，如果是就执行afterSingletonsInstantiated方法finishRefresh();完成BeanFactory的初始化创建工作，IOC容器创建完成123456789101112131415protected void finishRefresh() { // 清空上下文资源缓存 clearResourceCaches(); // 初始化生命周期相关后置处理 initLifecycleProcessor(); // 拿到声明周期处理器，回调容器刷新完成方法 getLifecycleProcessor().onRefresh(); // 发布容器刷新完成事件 publishEvent(new ContextRefreshedEvent(this)); LiveBeansView.registerApplicationContext(this);}这一步主要就是完成一些收尾工作：初始化生命周期相关后置处理器；我们可以写一个LifecycleProcessor的实现类，可以在BeanFactory刷新完成和关闭的时候进行一次自定义操作。拿到生命周期处理器（LifecycleProcessor），回调容器刷新完成方法发布容器刷新完成事件总结Spring容器启动时，会保存所有注册进来的Bean定义信息；xml、注解方式Spring容器会在合适的时机创建这些注册好的Bean，使用这个Bean的时候，利用getBean()创建Bean，创建完成以后保存在容器中；方法finishBeanFactoryInitialization(beanFactory);统一创建剩下的单实例Bean；后置处理器：每一个Bean注册完成后，都会使用各种后置处理器进行处理，来增强Bean的功能；AutowireAnnotationBeanPostProcessor【处理自动注入】、AnnotationAwareAspectJProxyCreator【AOP功能】、AsyncAnnotationBeanPostProcessor【异步处理接口】事件驱动模型：ApplicationListener【事件监听】、ApplicationEventMulticaster【事件派发】","link":"/2020/12/1608132723882/"},{"title":"Spring Bean 生命周期","text":"实例化Bean设置Bean属性值判断是否实现BeanNameAware，如果实现调用其setBeanName方法判断是否实现BeanFactoryAware，如果实现调用其setBeanFactory方法判断是否实现ApplicationContextAware，如果实现调用其setApplicationContext方法调用BeanPostProcessor的预初始化方法判断是否标注@PostConstruct注解，如果有则执行判断是否实现InitializingBean，如果实现调用其afterPropertiesSet方法判断是否配置初始化方法（init-method）调用BeanPostProcessor的后初始化方法是否为singletonsingleton: 将Bean放入SpringIOC的缓存池中prototype: 将Bean交给调用者，后续不进行管理（不参与后续步骤）执行@PreDestory标注的方法调⽤DisposableBean的destory⽅法调⽤属性配置的销毁⽅法（destory-method）","link":"/2020/11/1605760727911/"},{"title":"MySQL体系架构","text":"Client Connectors（客户端连接层）负责处理客户端的连接请求。几乎支持所有的连接类型。MySQL Server（服务层）Connection Pool（连接池）：负责处理存储数据库与客户端创建的连接，一个线程负责管理一个连接。它包含了用户认证、连接线程池、连接限制、内存与缓存管理。Services&amp;utilities（系统管理和控制工具）：管理服务&amp;工具集，包括备份恢复、安全管理、集群管理服务和工具。SQL Interface（SQL接口）：负责接收客户端发送的各种SQL命令，DML、DDL和存储过程等。Parser（解析器）：对SQL语句进行词法分析和语法分析生成解析树。Optimizer（查询优化器）：根据生成的解析树生成一个执行计划，并选择合适的索引，然后与存储引擎进行交互。会根据 选择 —&gt; 投影 —&gt; 连接 策略进行优化，如：select uid,name from user where gerder = 1; 。选择：select 根据where语句进行选取，并不是查询出所有数据在过滤。投影：select查询根据uid和name进行投影，并不是取出所有字段。连接：将两个查询条件连接起来，最终生成查询结果。Caches（缓存）：缓存机制是由一系列小缓存组成的。比如：表缓存、记录缓存、权限缓存、引擎缓存等。如果缓存中命中了查询结果，则直接在缓存中取数据，无需再与存储引擎交互。Pluggable Storage Engines（存储引擎层）主要负责MySQL数据的读写，与底层文件系统进行交互。MySQL的存储结构是插件式的，服务层中的查询执行引擎通过特定接口与存储引擎进行交互，接口屏蔽了不同存储引擎的差异。目前常见的存储引擎有：MyISAM、InnoDB。存储引擎是针对表的，而不是针对库的。File System（文件系统）该层负责将数据库的数据和日志文件存储在文件系统之上，并完成与存储引擎的交互，是文件的物理存储层。主要包含：日志文件、数据文件、配置文件、PID文件、socket文件等。日志文件Error Log（错误文件）：默认开启，可以通过show variables like '%log_err%';命令查询是否开启。General query log（通用查询日志）：记录一站查询语句，默认关闭，可以通过show variables like '%general%';命令查询是否开启。binary log（二进制日志）：记录了对MySQL数据库执行的一些更改操作，并且记录了语句发生的时间、执行时长；但是它不记录select、show等不修改数据库的SQL。主要用于数据恢复和主从复制。可以通过show variables like '%log_bin%';命令查询查看是否开启；show variables like '%binlog%';查看参数；show binary logs;查看日志文件。Slow query log（慢查询日志）：记录所有执行时间超时的查询SQL，默认是10秒。show variables like '%slow_query%';查询慢查询日志是否开启；show variables like '%long_query_time%';查看超时时间；set [global] long_query_time=5;重设超时时间，global代表全局修改，默认当前session生效。Config File（配置文件）用于存放MySQL所有的配置信息文件。如：my.cnf、my.ini等。数据文件db.opt文件：记录这个库默认使用的字符集和校验规则。frm文件：存储与表相关的元数据（mate）信息，包括表的结构和定义信息等，每一张表都会有一个frm文件。MYD文件：MyISAM存储引擎专用，存储MyISAM表的数据（data）相关信息，每一张表会有一个.MYD文件。MYI文件：MyISAM存储引擎专用，存储MyISAM表的索引（index）相关信息，每一张表对应一个.MYI文件。ibd文件和ibdata文件：存放InnoDB的数据文件（包括索引）。InnoDB存储引擎有两种表空间方式：独享表空间和共享表空间。独享表空间用.ibd文件存放数据，且每一张InnoDB表对应一个.ibd文件；共享表空间使用.ibdata文件存放数据，所有表共同使用一个或多个（自行配置）.ibdata文件ibdata1文件：系统表空间数据文件，存储表元数据文件，存储表元数据、Undo日志等。ib_logfile0、ib_logfile1文件：Redo Log文件。pid文件pid 文件是 mysqld 应用程序在 Unix/Linux 环境下的一个进程文件，和许多其他 Unix/Linux 服务 端程序一样，它存放着自己的进程 id。socket文件socket 文件也是在 Unix/Linux 环境下才有的，用户在 Unix/Linux 环境下客户端连接可以不通过 TCP/IP 网络而直接使用 Unix Socket 来连接 MySQL。MySQL的后台线程MySQL的服务实现通过后台多个线程、内存池、文件交互来实现对外服务的，不同线程实现不同的资源操作，各个线程相互协助，共同来完成数据库的服务。 整体上看，MySQL的后台线程概括如下，分为Master Thread、IO Thread、Purge Thread、Page Cleaner Thread","link":"/2020/09/1600589354839/"},{"title":"Spring Framework 5.0.x 模块组成、体系结构、整体架构","text":"核心容器（Core Containe）核心容器提供了Spring框架的基本功能，是其它模块建立的基础，有 spring-core、spring-beans、spring-context、spring-context-support和spring-expression（Expression Language、SpEL）组成。spring-beans和spring-core是spring框架的核心模块。spring-core提供了框架的基本组成部分，包括控制翻转(Inversion of Control, IOC)和依赖注入(Dependency Injection, DI)功能。spring-beans提供了BeanFactory，BeanFactory接口是spring框架中的核心接口，它是工厂模式的经典实现。BeanFactory使用控制翻转对应用程序的配置和依赖性规范与实际的应用程序代码进行了分离。但BeanFactory容器实例化后并不会自动创建实例化Bean，只有当Bean被使用的时候BeanFactory容器才会对该Bean进行实例化与依赖关系的装配。spring-contextspring-context模块构架与spring-core和spring-beans模块之上，提供了一个框架式的对象访问方式，是访问定义和配置的任意对象的媒介。它扩展了BeanFactory，为其增加了Bean生命周期控制、框架事件体系以及资源加载透明化等功能。ApplicationContext是该模块的核心接口，它是BeanFactory的子类，与BeanFactory不同的是ApplicationContext容器实例化后会自动对所有的单实例Bean进行实例化与依赖关系的装配，使之处于待用状态。spring-context-support用于将常见的第三方库集成到spring应用程序上下文中。该模块提供了高速缓存、任务调度、邮件访问等支持。spring-expression该模块是对JSP2.1规范中规定的统一表达式语言EL的扩展模块，它提供了强大的表达式语言去支持运行时查询和操作运行中的对象，该语言支持设置和获取属性值、属性分配、方法调用、访问数组、集合和索引器的内容、逻辑和算术运算、变量命名以及从Spring的IOC容器中以名称检索对象。它还支持列表投影、选择以及常用的列表聚合。它的语法类似于传统的EL，但提供了额外的功能。最出色的要数函数调用和简单字符串的模板函数。这种语言的特性是基于 spring 产品的需求而设计， 他可以非常方便地同 spring IOC 进行交互。AOP 和设备支持（AOP）由spring-aop、spring-aspects和 spring-instrument 3个模块组成。spring-aopspring-aop 是spring的另一个核心模块，提供了一个符合AOP要求的面相切面的编程实现。作为继OOP之后，对程序员影响最大的编程思想之一，AOP极大的开拓了人们对于编程的思路。在spring中，以JDK动态代理的技术为基础，设计出了一系列的AOP横切实现，比如：前置通知、返回通知和异常通知等。同时使用 Pointcut 接口匹配切入点，可以使用现有的切入点设计横切面；也可以扩展相关方法根据需求进行切入，将代码按照功能进行分离，以便干净的解耦。spring-aspects提供了与AspectJ的集成功能，主要是为AOP提供了多种实现方法。spring-instrument该模块是spring-aop的一个支援模块，提供了类植入(Instrumentation)支持和类加载器的实现。主要作用于JVM启动时，生成一个代理类，程序员通过代理类在运行时修改类的字节，从而改变一个类的功能，实现AOP的功能。数据访问与集成（Data Access/Integration）由spring-jdbc、spring-orm、spring-oxm、spring-jms和spring-tx组成。spring-jdbcspring-jdbc模块是spring提供的JDBC抽象层，消除了繁琐的编码以及数据库厂商特有的错误代码解析。用于简化JDBC，主要提供JDBC的模板方法、关系数据库对象化方式、事务管理来简化JDBC编程，主要实现类有JdbcTemplate、SimpleJdbcTemplate以及NamedParameterJdbcTemplate。spring-ormspring-orm模块是ORM的支持模块，主要集成Hibernate、Java Persistence API(JPA)和Java Data Object(JDO)用于资源管理、数据访问对象（DAO）的实现和事务策略。spring-oxmspring-oxm模块主要提供一个抽象层支撑OXM(Object-to-XML-Mapping)，例如：JAXB、Castor、XMLBeans、JiBX和XStream等。spring-jmsspring-jms模块（Java Message Service）为Java消息传递服务，能够发送和接收信息，自Spring Framework 4.1 以后，它还提供了对spring-messaging模块的继承。spring-txspring-tx模块是spring-jdbc事务控制实现模块，支持用于实现所有接口和所有POJO(普通Java对象)类的编程和声明式事务的管理。Web由spring-websocket、spring-webmvc、spring-web和spring-webflux组成spring-webspring-web模块为spring提供了最基础的web支持，主要建立在核心容器之上，通过Servlet或者Listeners来初始化IOC容器以及Web应用上下文，自动装载WebApplicationContext，也包含一些与web相关的支持，如：Struts集成类、文件上传支持的类、FIlter类和大量辅助工具类。spring-webmvc也称web-servlet模块，包含用于Web应用程序的Spring MVC和REST Web Service实现。Spring MVC框架提供了领域模型代码和Web表单之间的清晰分离，并与Spring Framework的所有其他功能集成。spring-websocketSpring4.0以后新增的模块，实现双工异步通讯协议，实现了WebSocket和SocketJS，提供Socket通信和Web端的推送功能。spring-webflux是一个新的非堵塞函数式Reactive Web框架，可以用来建立异步的，非阻塞，事件驱动的服务，并且扩展性非常好。消息（Messaging）spring-messagingspring-messaging是从 Spring4.0 开始新加入的一个模块，主要职责是为 Spring 框架集成一些基础的报文传送应用。Testspring-testspring-test模块主要为测试提供支持的，毕竟在不需要发布（程序）到你的应用服务器或者连接到其他企业设施的情况下能够执行一些集成测试或者其他测试对于任何企业都是非常重要的。spring 各模块依赖关系参考文章：https://blog.csdn.net/lj1314ailj/article/details/80118372https://blog.csdn.net/ThinkWon/article/details/102810819","link":"/2020/09/1599114101197/"},{"title":"什么是 IoC？什么是 DI？它们之间是什么关系？","text":"什么是控制反转（IOC）Ioc—Inversion of Control，即“控制反转”，它是一种设计思想，并不是什么技术；在 Java 中，IOC 意味着将我们设计好的对象交给容器控制，而不是传统的需要时在内部构造直接控制；谁控制谁？控制了什么？谁控制了谁： IoC 控制了对象；控制了什么： 主要控制了外部资源的获取，不仅限于对象，包括文件等资源；什么为正转？什么为反转？正转：在我们需要某个对象的时候，需要自己主动的去构建对象以及其所依赖的对象；反转：在我们需要某个对象的时候，只需要在 IoC 容器中获取所需对象，无需关心创建过程以及其中的依赖对象；全盘由 IoC 容器帮我们创建对象以及注入其所依赖的对象，在这里我们把对象的控制权反转给了 IoC 容器，所以称为反转；举个例子在现实生活中，当我们要用到一样东西的时候，第一反应是去找到这样东西，当我们想吃红烧肉的时候，如果没有饭店的支持，我们需要准备：肉、油、白砂糖、佐料等等一系列东西，然后自己去做，在这个过程中，所有的东西都是自己创造的这个过程称为正转；然而到了今天，生活变好了加上互联网的兴起，当我们想吃红烧肉的时候，第一反应是去外卖平台描述出我们的需求，通过提供联系方式和送货地址，最后下订单，过一会儿就会有人给我们把红烧肉送过来，在这个过程中，我们并没有主动的去创造红烧肉，红烧肉是外卖平台上的商家创造的，但也完全达到了我们的需求，这个过程称为反转。什么是依赖注入（DI）DI-Dependency Injection，即”依赖注入”，就是由容器动态的将某个依赖注入到组件中。通过依赖注入机制，我们只需要简单的配置，无需任何代码就可以指定目标所需要的资源，从而完成自身的业务逻辑；我们无需关心具体的资源来自何处，提升了系统灵活性和可扩展性。IOC和DI的关系DI 可以看作是 IoC 的一种实现方式，IoC 是一种思想，而 DI 是一种设计模式，是一种实现 IoC 的模式。依赖注入的三种方式构造方法注入： 被注入的对象可以通过在其构造方法中声明参数列表，让 IoC 容器知道它需要依赖哪些对象setter 注入： 为其需要依赖的对象增加 setter 方法，可以通过 setter 方法将其依赖的对象注入到对象中接口注入： 对于接口注入来说，如果被注入对象想要 IoC 容器为其注入依赖对象，就必须实现某个接口，这个接口提供了一个方法，用来为其注入依赖对象。但是从注入方式的使用来说，接口注入是现在不提倡的一种方式，基本处于”退役”状态，因为它强制被注入实现对象不必要的依赖。","link":"/2020/05/1589877993415/"},{"title":"为什么StringBuilder是线程不安全的？StringBuffer是线程安全的？","text":"面试中经常问到的一个问题：StringBuilder和StringBuffer的区别是什么？我们非常自信的说出：StringBuilder是线程不安全的，StirngBuffer是线程安全的面试官：StringBuilder不安全的点在哪儿？这时候估计就哑巴了。。。分析StringBuffer和StringBuilder的实现内部是和String内部一样的，都是通过 char[]数组的方式；不同的是String的char[]数组是通过final关键字修饰的是不可变的，而StringBuffer和StringBuilder的char[]数组是可变的。首先我们看下边这个例子：123456789101112131415public class Test { public static void main(String[] args) throws InterruptedException { StringBuilder stringBuilder = new StringBuilder(); for (int i = 0; i &lt; 10000; i++){ new Thread(() -&gt; { for (int j = 0; j &lt; 1000; j++){ stringBuilder.append(\"a\"); } }).start(); } Thread.sleep(100L); System.out.println(stringBuilder.length()); }}直觉告诉我们输出结果应该是10000000，但是实际运行结果并非我们所想。从上图可以看到输出结果是9970698，并非是我们预期的1000000（什么情况？剩下的那些都被计算机吃了？），并且还抛出了一个异常ArrayIndexOutOfBoundsException（吃了我的东西还给我吐出来个异常）{非必现}为什么输出结果并非预期值？我们先看一下StringBuilder的两个成员变量（这两个成员变量实际上是定义在AbstractStringBuilder里面的，StringBuilder和StringBuffer都继承了AbstractStringBuilder）StringBuilder的append方法StringBuilder的append方法调用了父类的append方法我们直接看第七行代码，count += len; 不是一个原子操作，实际执行流程为首先加载count的值到寄存器在寄存器中执行 +1操作将结果写入内存假设我们count的值是10，len的值为1，两个线程同时执行到了第七行，拿到的值都是10，执行完加法运算后将结果赋值给count，所以两个线程最终得到的结果都是11，而不是12，这就是最终结果小于我们预期结果的原因。为什么会抛出ArrayIndexOutOfBoundsException异常？我们看回AbstractStringBuilder的追加（）方法源码的第五行，ensureCapacityInternal（）方法是检查StringBuilder的对象的原字符数组的容量能不能盛下新的字符串，如果盛不下就调用expandCapacity（）方法对字符数组进行扩容。12345private void ensureCapacityInternal（int minimumCapacity） { //溢出意识代码 if （minimumCapacity - value .length&gt; 0） expandCapacity（minimumCapacity）; }扩容的逻辑就是新一个新的字符数组，新的字符数组的容量是原来字符数组的两倍再加2，再通过System.arryCopy（）函数将原数组的内容复制到新数组，最后将指针指向新的字符数组。1234567void expandCapacity（int minimumCapacity） { //计算新的容量 int newCapacity = value .length * 2 + 2 ; //中间省略了一些检查逻辑 ... value = Arrays.copyOf（ value，newCapacity）; }Arrys.copyOf（）方法1234567public static char [] copyOf（char [] original， int newLength） { char [] copy = new char [newLength]; //拷贝数组 System.arraycopy（original， 0，copy， 0， Math.min（original.length，newLength））; 返回 副本; }AbstractStringBuilder的追加（）方法源码的第六行，是将字符串对象里面字符数组里面的内容拷贝到StringBuilder的对象的字符数组里面，代码如下：1str.getChars（0，len， value，count）;则GetChars（）方法12345public void getChars（int srcBegin， int srcEnd， char dst []， int dstBegin） { //中间省略了一些检查 ... System.arraycopy（ value，srcBegin，dst，dstBegin，srcEnd - srcBegin）; }拷贝流程见下图假设现在有两个线程同时执行了StringBuilder的append()方法，两个线程都执行完了第五行的ensureCapacityInternal()方法，此刻count=5这个时候线程1的cpu时间片用完了，线程2继续执行。线程2执行完整个append()方法后count变成6了。线程1继续执行第六行的str.getChars()方法的时候拿到的count值就是6了，执行char[]数组拷贝的时候就会抛出ArrayIndexOutOfBoundsException异常。至此，StringBuilder为什么不安全已经分析完了。如果我们将测试代码的StringBuilder对象换成StringBuffer对象会输出什么呢？结果肯定是会输出 1000000，至于StringBuffer是通过什么手段实现线程安全的呢？看下源代码就明白了了。。。","link":"/2019/09/1568887656676/"},{"title":"Java实践-远程调用Shell脚本并获取输出信息","text":"1、添加依赖12345678910&lt;dependency&gt; &lt;groupId&gt;ch.ethz.ganymed&lt;/groupId&gt; &lt;artifactId&gt;ganymed-ssh2&lt;/artifactId&gt; &lt;version&gt;262&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt;2、Api说明首先构造一个连接器，传入一个需要登陆的ip地址；1Connection conn = new Connection(ipAddr);模拟登陆目的服务器，传入用户名和密码；1boolean isAuthenticated = conn.authenticateWithPassword(userName, passWord);它会返回一个布尔值，true 代表成功登陆目的服务器，否则登陆失败。打开一个session，执行你需要的linux 脚本命令；12Session session = conn.openSession();session.execCommand(“ifconfig”);接收目标服务器上的控制台返回结果，读取br中的内容；12InputStream stdout = new StreamGobbler(session.getStdout());BufferedReader br = new BufferedReader(new InputStreamReader(stdout));得到脚本运行成功与否的标志 ：0－成功 非0－失败1System.out.println(“ExitCode: ” + session.getExitStatus());关闭session和connection12session.close();conn.close();Tips：通过第二部认证成功后当前目录就位于/home/username/目录之下，你可以指定脚本文件所在的绝对路径，或者通过cd导航到脚本文件所在的目录，然后传递执行脚本所需要的参数，完成脚本调用执行。执行脚本以后，可以获取脚本执行的结果文本，需要对这些文本进行正确编码后返回给客户端，避免乱码产生。如果你需要执行多个linux控制台脚本，比如第一个脚本的返回结果是第二个脚本的入参，你必须打开多个Session,也就是多次调用Session sess = conn.openSession();,使用完毕记得关闭就可以了。3. 实例：工具类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class SSHTool { private Connection conn; private String ipAddr; private Charset charset = StandardCharsets.UTF_8; private String userName; private String password; public SSHTool(String ipAddr, String userName, String password, Charset charset) { this.ipAddr = ipAddr; this.userName = userName; this.password = password; if (charset != null) { this.charset = charset; } } /** * 登录远程Linux主机 * * @return 是否登录成功 */ private boolean login() { conn = new Connection(ipAddr); try { // 连接 conn.connect(); // 认证 return conn.authenticateWithPassword(userName, password); } catch (IOException e) { e.printStackTrace(); return false; } } /** * 执行Shell脚本或命令 * * @param cmds 命令行序列 * @return 脚本输出结果 */ public StringBuilder exec(String cmds) throws IOException { InputStream in = null; StringBuilder result = new StringBuilder(); try { if (this.login()) { // 打开一个会话 Session session = conn.openSession(); session.execCommand(cmds); in = session.getStdout(); result = this.processStdout(in, this.charset); conn.close(); } } finally { if (null != in) { in.close(); } } return result; } /** * 解析流获取字符串信息 * * @param in 输入流对象 * @param charset 字符集 * @return 脚本输出结果 */ public StringBuilder processStdout(InputStream in, Charset charset) throws FileNotFoundException { byte[] buf = new byte[1024]; StringBuilder sb = new StringBuilder();// OutputStream os = new FileOutputStream(\"./data.txt\"); try { int length; while ((length = in.read(buf)) != -1) {// os.write(buf, 0, c); sb.append(new String(buf, 0, length)); } } catch (IOException e) { e.printStackTrace(); } return sb; } public static void main(String[] args) throws IOException { SSHTool tool = new SSHTool(\"192.168.100.40\", \"root\", \"123456\", StandardCharsets.UTF_8); StringBuilder exec = tool.exec(\"bash /root/test12345.sh\"); System.out.println(exec); }}4、测试脚本1echo \"Hello\"输出结果","link":"/2019/09/1568023812560/"},{"title":"浅谈关于SQL优化的思路","text":"零、为什么要优化系统的吞吐量瓶颈往往出现在数据库的访问速度上随着应用程序的运行，数据库的中的数据会越来越多，处理时间会相应变慢数据是存放在磁盘上的，读写速度无法和内存相比一、观察MySQL优化≠SQL语句优化，理解这一点非常重要，虽然大部分时候我们都在调优SQL语句。然而，MySQL的优化却是始于观察，而且有时候观察几分钟，几小时就能得出结论的，可能要观察一天以上。这么做的目的很明显，就是为了帮助我们定位问题所在。比如：MySQL的负载会在固定的某个时间节点突然暴涨，或者一请求某几个页面就产生了较为明显的延迟，甚至影响了随后的各个请求等。观察的手段有多种多样，阿里云有强大的RDS控制台，也可以自建一套监控平台，最次的就是临时跑个shell脚本，收集MySQL运行状况。观察的指标也不尽相同，最知名的 show status 命令列出的指标就能不下200个，所以观察也要有所取舍。经常受人关注的指标有当前连接数以及最大连接数，当前运行的线程数，慢查询数量等。二、分析将观察的结果做进一步分析，也就形成了不同的解决思路。可能是某个时间节点缓存失效，导致MySQL的负载激增，可以设法将缓存失效的时间节点尽可能均匀的分摊在一天24小时中，或者找个访问量较少的时段刷新缓存。可能是SQL语句存在潜在问题，在某些情况下会有性能问题，可以用 show full processlist 定位是哪个库，也可以开启慢查询，直接定位到有问题的SQL语句，使用explain分析语句执行计划。可能加个索引能解决问题，也有可能join太多表，需要拆分查询，也有可能单表体量过大，要拆表了。可能是机器本身性能问题，所谓“巧妇难为无米之炊”，这个时候要考虑扩容了。三、解决在分析阶段已经提及了大部分解决手段了，最后总结一下：1、引入缓存，当然，这是一把双刃剑，要想用的恰如其分，还是需要一定的功力。缓存也分两方面的，一方面是MySQL的内部缓存机制，MySQL提供了多种缓存参数的配置，比如查询的结果集缓存，结果集排序的缓存，可根据实际情况进行调整。另一方面是MySQL之外的缓存，比如Redis+MySQL的架构，开启了Hibernate（Mybatis）的缓存功能。缓存的引入无非是想减轻MySQL的查询负担，但是必须在性能稳定性与数据时效性之间取得平衡。2、SQL语句有性能问题，这种情况时有发生，通常是上线之前未能做一个完整的基准测试，而只是简单的功能性测试。当数据量积累到一定程度之后，SQL性能问题就集中爆发出来了。所以，在写完SQL之后，要养成explain的习惯，将潜在的性能问题扼杀在萌芽中。当然，我们也要避免“过度优化”，我们要预见得到一张表是读取次数多，还是更新次数多，数据量会不会爆发性增长，还是增长十分缓慢。当然，写SQL语句也要遵循一定的原则，比如什么时候用IN查询，什么时候用EXISTS谓词，在JOIN之前是不是可以精简一部分表数据，建立的索引能否正确派上用场……3、必要的时候，可以对机器进行扩容，当然系统的整体架构也可以考虑进行优化，搭建MySQL集群，可靠性和可用性都能得到大幅提升。四、补充：SQL范式1NF每一个分量必须是不可分的数据项。特点：有主键，且主键不能为空。字段不能再分。2NF在范式一的基础上，且每一个非主属性完全函数依赖于码。特点：满足第一范式。表中的每一个非主属性，必须完全依赖于本表码。只有当一个表中，主码由两个或以上的属性组成的时候，才会出现不符合第二范式的情况。3NF在满足第二范式的基础上，且每一个非主属性既不部分依赖于码也不传递依赖于码。特点：满足第二范式。非主属性不能传递依赖于码。BCNF在满足第三范式的基础上，且不允许主键的一部分被另一部分或其它部分决定。特点：满足第三范式。所有非主属性对每一个码都是完全函数依赖。所有的主属性对每一个不包含它的码，也是完全函数依赖。没有任何属性完全函数依赖于飞码的任何一组属性。以上是对MySQL优化的框架性思考。","link":"/2019/09/1567698802009/"},{"title":"Docker搭建Zookeeper&Kafka集群","text":"前排提示：最新的docker-compole.yml请去github获取，README有相应的操作步骤。Github地址：https://github.com/JacianLiu/docker-compose最近在学习Kafka，准备测试集群状态的时候感觉无论是开三台虚拟机或者在一台虚拟机开辟三个不同的端口号都太麻烦了（嗯。。主要是懒）。环境准备一台可以上网且有CentOS7虚拟机的电脑为什么使用虚拟机？因为使用的笔记本，所以每次连接网络IP都会改变，还要总是修改配置文件的，过于繁琐，不方便测试。（通过Docker虚拟网络的方式可以避免此问题，当时实验的时候没有了解到）Docker 安装如果已经安装Docker请忽略此步骤Docker支持以下的CentOS版本：CentOS 7 (64-bit)：要求系统为64位、系统内核版本为 3.10 以上。CentOS 6.5（64-bit）或更高的版本：要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本。CentOS 仅发行版本中的内核支持 Docker。yum安装Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看上文的前提条件来验证你的CentOS 版本是否支持 Docker 。12# 查看内核版本$ uname -a12#安装 Docker$ yum -y install docker12#启动 Docker 后台服务$ service docker start12# 由于本地没有hello-world这个镜像，所以会下载一个hello-world的镜像，并在容器内运行。$ docker run hello-world脚本安装使用 sudo 或 root 权限登录 Centos。确保 yum 包更新到最新。1$ sudo yum update获取并执行 Docker 安装脚本。123$ curl -fsSL https://get.docker.com -o get-docker.sh# 执行这个脚本会添加 docker.repo 源并安装 Docker。$ sudo sh get-docker.sh启动Docker1$ sudo systemctl start docker123# 验证 docker 是否安装成功并在容器中执行一个测试的镜像。$ sudo docker run hello-world$ docker ps镜像加速开始让我配置国内镜像源的时候我是拒绝的，但是使用之后发现那下载速度 duang~ 的一下就上去了。所以强烈建议大家配置国内镜像源。打开/创建 /etc/docker/daemon.json 文件，添加以下内容：123{ \"registry-mirrors\": [\"http://hub-mirror.c.163.com\"]}Zookeeper集群搭建Zookeeper镜像：zookeeper:3.4镜像准备1$ docker pull zookeeper:3.4查找镜像可以去 https://hub.docker.com/docker pull images:TAG // 代表拉取 TAG 版本的 image 镜像建立独立Zookeeper容器我们首先用最简单的方式创建一个独立的Zookeeper节点，然后我们根据这个例子创建出其他的节点。1$ docker run --name zookeeper -p 2181:2181 -d zookeeper:3.4默认的，容器内配置文件在， /conf/zoo.cfg，数据和日志目录默认在 /data 和 /datalog，需要的话可以将上述目录映射到宿主机。参数解释–name：指定容器名字-p：为容器暴露出来的端口分配端口号-d：在后台运行容器并打印容器ID集群搭建其它节点的Zookeeper容器创建方式与创建独立容器类似，需要注意的是，要分别指定节点的id和修改文件中多节点的配置，相应的创建命令如下：新建docker网络12$ docker network create zoo_kafka$ docker network lsZookeeper容器11234567891011$ docker run -d \\ --restart=always \\ -v /opt/docker/zookeeper/zoo1/data:/data \\ -v /opt/docker/zookeeper/zoo1/datalog:/datalog \\ -e ZOO_MY_ID=1 \\ -p 2181:2181 \\ -e ZOO_SERVERS=&quot;server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888&quot; \\ --name=zoo1 \\ --net=viemall-zookeeper \\ --privileged \\ zookeeper:3.4Zookeeper容器21234567891011$ docker run -d \\ --restart=always \\ -v /opt/docker/zookeeper/zoo2/data:/data \\ -v /opt/docker/zookeeper/zoo2/datalog:/datalog \\ -e ZOO_MY_ID=2 \\ -p 2182:2181 \\ -e ZOO_SERVERS=&quot;server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888&quot; \\ --name=zoo2 \\ --net=viemall-zookeeper \\ --privileged \\ zookeeper:3.4Zookeeper容器31234567891011$ docker run -d \\ --restart=always \\ -v /opt/docker/zookeeper/zoo3/data:/data \\ -v /opt/docker/zookeeper/zoo3/datalog:/datalog \\ -e ZOO_MY_ID=3 \\ -p 2183:2181 \\ -e ZOO_SERVERS=&quot;server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888&quot; \\ --name=zoo3 \\ --net=viemall-zookeeper \\ --privileged \\ zookeeper:3.4这种方式虽然也实现了我们想要的，但是步骤过于繁琐，而且维护起来麻烦（懒癌晚期），所以我们使用 docker-compose 的方式来实现。docker-compose 搭建zookeeper集群新建docker网络12$ docker network create --driver bridge --subnet 172.23.0.0/25 --gateway 172.23.0.1 zoo_kafka$ docker network ls编写 docker-compose.yml 脚本使用方式：安装 docker-compose1234# 获取脚本$ curl -L https://github.com/docker/compose/releases/download/1.25.0-rc2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose# 赋予执行权限$chmod +x /usr/local/bin/docker-compose任意目录下新建 docker-compose.yml 文件，复制以下内容执行命令 docker-compose up -d命令对照命令解释docker-compose up启动所有容器docker-compose up -d后台启动并运行所有容器docker-compose up –no-recreate -d不重新创建已经停止的容器docker-compose up -d test2只启动test2这个容器docker-compose stop停止容器docker-compose start启动容器docker-compose down停止并销毁容器docker-compose.yml下载地址：https://github.com/JacianLiu/docker-compose/tree/master/zookeeperdocker-compose.yml详情123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566version: '2'services: zoo1: image: zookeeper:3.4 # 镜像名称 restart: always # 当发生错误时自动重启 hostname: zoo1 container_name: zoo1 privileged: true ports: # 端口 - 2181:2181 volumes: # 挂载数据卷 - ./zoo1/data:/data - ./zoo1/datalog:/datalog environment: TZ: Asia/Shanghai ZOO_MY_ID: 1 # 节点ID ZOO_PORT: 2181 # zookeeper端口号 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 # zookeeper节点列表 networks: default: ipv4_address: 172.23.0.11 zoo2: image: zookeeper:3.4 restart: always hostname: zoo2 container_name: zoo2 privileged: true ports: - 2182:2181 volumes: - ./zoo2/data:/data - ./zoo2/datalog:/datalog environment: TZ: Asia/Shanghai ZOO_MY_ID: 2 ZOO_PORT: 2181 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: default: ipv4_address: 172.23.0.12 zoo3: image: zookeeper:3.4 restart: always hostname: zoo3 container_name: zoo3 privileged: true ports: - 2183:2181 volumes: - ./zoo3/data:/data - ./zoo3/datalog:/datalog environment: TZ: Asia/Shanghai ZOO_MY_ID: 3 ZOO_PORT: 2181 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: default: ipv4_address: 172.23.0.13networks: default: external: name: zoo_kafka验证从图中我们可以看出，有一个Leader，两个Flower，至此我们的Zookeeper集群就已经搭建好了Kafka集群搭建有了上面的基础，再去搞Kafka集群还是问题吗？其实就是几个变量值不同而已。有了上边的例子，就不费劲去搞单节点的Kafka了，直接使用docker-compose的方式，部署三个节点，其实方式大同小异，上边也说到，其实就是一些属性不同而已；这时候我们就不需要再去新建 Docker 网络了，直接使用前边搭建 Zookeeper 集群时创建的网络即可！环境准备Kafka镜像：wurstmeister/kafkaKafka-Manager镜像：sheepkiller/kafka-manager123# 不指定版本默认拉取最新版本的镜像docker pull wurstmeister/kafkadocker pull sheepkiller/kafka-manager编写 docker-compose.yml 脚本使用方式：安装 docker-compose1234# 获取脚本$ curl -L https://github.com/docker/compose/releases/download/1.25.0-rc2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose# 赋予执行权限$chmod +x /usr/local/bin/docker-compose任意目录下新建 docker-compose.yml 文件，复制以下内容执行命令 docker-compose up -d命令对照|命令|解释||-|-||docker-compose up|启动所有容器||docker-compose up -d|后台启动并运行所有容器||docker-compose up –no-recreate -d|不重新创建已经停止的容器||docker-compose up -d test2|只启动test2这个容器||docker-compose stop|停止容器||docker-compose start|启动容器||docker-compose down|停止并销毁容器|docker-compose.yml下载地址：https://github.com/JacianLiu/docker-compose/tree/master/zookeeperdocker-compose.yml详细内容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112version: '2'services: broker1: image: wurstmeister/kafka restart: always hostname: broker1 container_name: broker1 privileged: true ports: - \"9091:9092\" environment: KAFKA_BROKER_ID: 1 KAFKA_LISTENERS: PLAINTEXT://broker1:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker1:9092 KAFKA_ADVERTISED_HOST_NAME: broker1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181/kafka1,zoo2:2181/kafka1,zoo3:2181/kafka1 JMX_PORT: 9988 volumes: - /var/run/docker.sock:/var/run/docker.sock - ./broker1:/kafka/kafka\\-logs\\-broker1 external_links: - zoo1 - zoo2 - zoo3 networks: default: ipv4_address: 172.23.0.14 broker2: image: wurstmeister/kafka restart: always hostname: broker2 container_name: broker2 privileged: true ports: - \"9092:9092\" environment: KAFKA_BROKER_ID: 2 KAFKA_LISTENERS: PLAINTEXT://broker2:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker2:9092 KAFKA_ADVERTISED_HOST_NAME: broker2 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181/kafka1,zoo2:2181/kafka1,zoo3:2181/kafka1 JMX_PORT: 9988 volumes: - /var/run/docker.sock:/var/run/docker.sock - ./broker2:/kafka/kafka\\-logs\\-broker2 external_links: # 连接本compose文件以外的container - zoo1 - zoo2 - zoo3 networks: default: ipv4_address: 172.23.0.15 broker3: image: wurstmeister/kafka restart: always hostname: broker3 container_name: broker3 privileged: true ports: - \"9093:9092\" environment: KAFKA_BROKER_ID: 3 KAFKA_LISTENERS: PLAINTEXT://broker3:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker3:9092 KAFKA_ADVERTISED_HOST_NAME: broker3 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181/kafka1,zoo2:2181/kafka1,zoo3:2181/kafka1 JMX_PORT: 9988 volumes: - /var/run/docker.sock:/var/run/docker.sock - ./broker3:/kafka/kafka\\-logs\\-broker3 external_links: # 连接本compose文件以外的container - zoo1 - zoo2 - zoo3 networks: default: ipv4_address: 172.23.0.16 kafka-manager: image: sheepkiller/kafka-manager:latest restart: always container_name: kafka-manager hostname: kafka-manager ports: - \"9000:9000\" links: # 连接本compose文件创建的container - broker1 - broker2 - broker3 external_links: # 连接本compose文件以外的container - zoo1 - zoo2 - zoo3 environment: ZK_HOSTS: zoo1:2181/kafka1,zoo2:2181/kafka1,zoo3:2181/kafka1 KAFKA_BROKERS: broker1:9092,broker2:9092,broker3:9092 APPLICATION_SECRET: letmein KM_ARGS: -Djava.net.preferIPv4Stack=true networks: default: ipv4_address: 172.23.0.10networks: default: external: # 使用已创建的网络 name: zoo_kafka验证我们打开kafka-manager的管理页面，访问路径是，宿主机ip:9000；如果所示，填写上Zookeeper集群的地址，划到最下边点击save点击刚刚添加的集群，可以看到，集群中有三个节点搭建过程中遇到的问题挂载数据卷无限重启，查看log提示：chown: changing ownership of ‘/var/lib/mysql/….‘: Permission denied解决方式：在docker run中加入 –privileged=true 给容器加上特定权限临时关闭selinux： setenforce 0添加selinux规则，改变要挂载的目录的安全性文本kafka-manager报jmx相关错误，解决方法：在每一个kafka节点加上环境变量 JMX_PORT=端口加上之后发现连不上，又是网络连接的问题，于是又把每个jmx端口暴露出来，然后fire-wall放行， 解决问题。KAFKA_ADVERTISED_HOST_NAME这个最好设置宿主机的ip,宿主机以外的代码或者工具来连接，后面的端口也需要设置暴露的端口。1[error] k.m.j.KafkaJMX$ - Failed to connect to service:jmx:rmi:///jndi/rmi://9.11.8.48:-1/jmxrmi java.lang.IllegalArgumentException: requirement failed: No jmx port but jmx polling enabled!在容器中查看topic时报以下错误（不仅仅是topic的命令，好像所有的都会出错）1234$ bin/kafka-topics.sh --list --zookeeper zoo1:2181/kafka1,zoo2:2181/kafka1,zoo3:2181/kafka1# 以下是错误Error: Exception thrown by the agent : java.rmi.server.ExportException: Port already in use: 7203; nested exception is: java.net.BindException: Address already in use解决方法：在命令前加上unset JMX_PORT;指令，上边的命令改造为：1$ unset JMX_PORT;bin/kafka-topics.sh --list --zookeeper zoo1:2181/kafka1,zoo2:2181/kafka1,zoo3:2181/kafka1附：Docker常用指令1234567891011121314151617181920# 查看所有镜像docker images# 查看所有运行中的容器docker ps# 查看所有容器docker ps -a# 获取所有容器ip$ docker inspect --format=&apos;{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}&apos; $(docker ps -aq)# 查看容器内部日志$ docker logs -f &lt;容器ID&gt;# 进入容器内部$ docker exec -it &lt;容器ID&gt; /bin/basj# 创建容器 -d代表后台启动docker run --name &lt;容器名称&gt; -e &lt;参数&gt; -v &lt;挂载数据卷&gt; &lt;容器ID&gt;# 重启容器docker restart &lt;容器ID&gt;# 关闭容器docker stop &lt;容器id&gt;# 运行容器docker start &lt;容器id&gt;","link":"/2019/08/1566883722264/"},{"title":"链表","text":"开篇问题问题：如何用链表来实现 LRU 缓存淘汰策略呢？链表的作用链表一个经典的应用场景就是LRU缓存淘汰算法；缓存是一种提高数据读取性能的技术，在开发中有着非常广泛的应用，由于缓存的大小有限，当缓存被占满时，哪些数据应该被清理，哪些数据应该被保留？这就需要淘汰策略来决定，常见的淘汰策略有三种：先进先出策略FIFO（First In, First Out）、最少使用策略LFU（Least Frequently Used）、最近最少使用策略LRU（Least Recently Used）。打个比方：假如说你买了很多书籍，但有一天发现书太多了，太占空间，你要做个大扫除。那么这个时候你会选择扔掉哪些书籍？对应一下，其实就是我们上边说的三种策略；什么是链表？为了理解起来更容易，我们拿数组来做对比；相比数组，链表是一种稍微复杂一点的数据结构。从底层的存储结构上来看：数组需要一块儿连续的内存空间，堆内存的要求比较高，如果我们申请一个100MB大小的数组，当内存中没有连续的、足够大的空间的时候，即便内存的剩余总可用空间大于100MB，仍然会申请失败；而链表恰恰相反，它并不需要一块儿连续的内存空间，它通过“指针”将一组零散的内存块串联起来，所以如果我们申请100MB大小的链表，如果没有100MB连续的内存空间，且内存的剩余总可用空间大于100MB，根本不会有问题；常见的链表结构链表的结构五花八门，今天重点来介绍下三种最常见的链表结构，分别是：单链表、双向链表和循环链表。单链表刚刚提到，链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块成为链表的“节点”。为了将所有的节点穿起来，每个节点除了存储数据以外，还需要记录链上的下一个节点的地址，我们把这个记录下个节点地址的指针叫做后继节点 next；从图中我们发现，有两个节点是比较特殊的，分别是第一个节点和最后一个节点。我们称第一个节点为头结点，最后一个节点叫做尾节点。其中头结点用来记录链表的基地址，有了它我们就可以遍历得到整条链表；而为节点特殊的地方是：指针不是指向下一个节点，而是指向一个空地址 NULL，表示这是链表上的最后一个节点；链表的增删改查我们在进行数组的插入、删除操作的时候，为了保持内存数据的连续性，需要进行大量的数据搬移工作，所以时间复杂度为 O(n)；而在链表中插入或者删除一个数据我们并不需要为了保持内存的连续性而搬移节点，因为链表本身的存储空间也不是连续的，所以在链表中插入和删除一个数据是非常快的；插入数据：我们只需要将要插入位置的前一个数据单元的next指针指向插入数据的内存地址，插入数据的next指针指向下一个数据的内存地址；删除数据：将要删除数据的前一个数据单元的next指针指向要删除数据的下一个数据单元的内存地址，然后再删除数据；但是，链表想要访问第k个元素时，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样根据首地址和下标，通过寻址公式就能计算出对应的内存空间，而是需要根据指针一个节点一个节点的依次遍历，直到找到相应的节点。链表就好比是在学校站队一样，假如我们都只知道自己后面的人是谁，如果我们想知道第k个人是谁，我们就需要从第一个人开始，一个一个的往下数。所以，链表随机访问的性能没有数组好，需要O(n)的时间复杂度；循环链表循环链表其实就是一种特殊的单链表，它根单链表唯一的区别就在于尾节点，上文我们提到单链表的尾节点的next指针指向空地址，表示这是最后的节点了；而循环链表的尾节点指针指向的是链表的头结点，如下图，它就像一个环一样收尾项链，所以叫做循环链表。和单链表相比，循环链表的优点是从链尾到连头比较方便，当要处理的数据具有环形特点时，就特别适合使用循环链表。双向链表单链表只有一个方向，节点只有一个后继指针next指向后面的节点。而双向链表支持两个方向，每个节点不仅有一个后继指针，还有一个前驱指针prev指向前面的节点。从图中我们不难看出，双向链表需要额外的两个空间来存储后继节点和前驱节点的地址。所以存储同样多的数据，双向链表占用的空间要大于单向链表。虽然内存的占用增大了，但是可以支持双向遍历，这样使得双向链表的操作更加灵活。双向链表相比单向链表：从结构上看，双向链表可以支持 O(1)时间复杂度下找到前驱节点，也使得双向链表在某些情况下的插入和删除等操作要比单链表更加的简单高效。在上文中我们说单向链表的时候，提到单链表的增加和删除操作的时间复杂度也是 O(1) ，但这种结果偏于理论，接下来我们通过实际的例子来分析。删除操作在实际开发中，从链表中删除一个数据无外乎两种情况：\u001b删除节点中“值等于某个给定的值”的节点；删除给定指针指向的节点；对于第一种情况，不管是单链表还是双链表，为了查找值等于给定值的节点，都需要从头节点开始一个一个依次遍历对比，知道找到值等于给定值的节点，然后在进行删除操作；尽管单纯的删除操作时间复杂度是O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)，根据时间复杂度分析中的加法法则，删除值等于给定值的节点对应的链表操作的总时间复杂为O(n)。对于第二种情况，我们已经找到了要删除的节点，但是删除某个节点 q ，需要知道其前驱节点，而单链表并不支持直接获取前驱节点，所以为了找到前驱节点，我们还是要从头节点开始遍历链表，直到找到 p-&gt;next=q，说明p是q的前驱节点；但是对于双向链表来讲，这种情况就比较有优势。因为双向链表中的节点已经保存了前驱节点的指针，不需要像单链表那样遍历。所以针对第二种情况，单链表删除的操作需要O(n)的时间复杂度，而双向链表只要O(1)的时间复杂度。同理，如果我们希望在链表的某个节点前面插入一个节点；双向链表比单链表有很大的优势。双向链表可以再O(1)的时间复杂度搞定，而单向链表需要O(n)的时间复杂度，可以参考上边删除操尝试自己分析一下；用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。链表&amp;数组性能对比数组和链表的存储方式截然不同，正是因为内存存储方式的不同，它们插入、删除、随机访问操作的时间复杂度正好相反；数组链表插入、删除O(n)O(1)随机访问O(1)O(n)不过在实际开发中要根据实际场景来选择具体的数据结构存储，不能仅仅通过时间复杂度来决定；数组简单易用，在实现上使用的是连续的内存空间，可以借助CPU的缓存机制，预读取数组中的数据，所以访问效率更高；而链表在内存中并不是连续的所以对CPU缓存不友好，没办法有效预读。数组的缺点是大小固定，已经声明就要占用整块连续的内存空间；如果声明数组过大，可能会导致内存不足，如果声明数组过小，可能会导致容量不够用，这是就需要在申请一个更大的内存空间，把原数组copy进去，非常耗时；链表本身没有大小的限制，天然支持动态扩容。虽然Java中的ArrayList也支持动态扩容，但是其本质就是当容量不足时去申请一个更大的空间去存储；解题开篇好了，关于链表的知识我们就讲完了。我们现在回过头来看下开篇留给你的思考题。如何基于链表实现 LRU 缓存淘汰算法？我的思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。如果此数据没有在缓存链表中，又可以分为两种情况：如果此时缓存未满，则将此结点直接插入到链表的头部；如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。如何判断一个字符串是否是回文字符串的问题？思路首先用一个快指针，一个慢指针来遍历链表。快指针每次走两步，慢指针每次走一步。等到快指针遍历完链表，慢指针就正好停留在链表的中央。将链表的后半部分进行反转。将链表的前半部分与后半部分逐个比对。若都相同，则为回文链表，否则不是。 链表遍历的时间复杂度大约为 n/2。反转的时间复杂度为n/2。逐个比对的复杂度为n/2，所以总体的时间复杂度为O(n).而其中用于暂存的节点只有两个。因此空间复杂度为O(1)。实现123456789101112131415161718192021222324252627282930313233class Solution { public boolean isPalindrome(ListNode head) { if (head == null || head.next == null) { return true; } ListNode prev = null; ListNode slow = head; ListNode fast = head; while (fast != null &amp;&amp; fast.next != null) { fast = fast.next.next; ListNode next = slow.next; slow.next = prev; prev = slow; slow = next; } if (fast != null) { slow = slow.next; } while (slow != null) { if (slow.val != prev.val) { return false; } slow = slow.next; prev = prev.next; } return true; }}","link":"/2019/08/1566712230071/"},{"title":"记录一次由于线程使用不当引发的血案","text":"背景最近给第三方做了一个接口，接口的作用是接收数据对数据进行验证之后通过kafka推送到模型进行数据处理，最终通过kafka接收模型的数据，开始只做了一个异步的接口，由于对方业务原因需要一个同步的接口传输数据，但是每当运行一段时间之后程序就会进入假死状态，接口无法正常调用；同步接口同步接口的实现是使用阻塞Map，当对方发送请求时，对数据进行验证，然后推送到模型，等待结果返回之后将处理好的数据推送到对方接口，此时这次请求给调用方返回相应信息；思路开始认为是由于用户量过大导致内存不足引发的程序假死，使用JMeter进行压力测试异步接口模拟10000个请求同时调用接口，程序如丝滑般运行，没有丝毫问题，所有请求都正常返回（这里由于在家里通过VPN连接的公司开发服务器，网络不稳定，所以就拿少量测试用例为例）；然后开始怀疑是不是同步接口出了问题，刚开始模拟少量请求，因为当时是在开发环境进行测试，模型并没有放上去，所以没有返回信息，一直在等待模型的返回结果，也是没有问题的，这时候调用异步接口也没有任何问题；思考：所有资源都是阻塞状态，因为没有处理结果，一直没有释放进程，当数据过大时会不会造成服务器资源耗尽，导致程序假死？当再次加大同步接口的调用次数的时候，再去尝试请求异步接口，发现异步接口也没有了返回信息，这时遍确认了问题所在；线程全部在阻塞状态，当太多资源没有释放掉时，服务器资源耗尽，导致程序无法正常运行；解决找到问题之后就是要解决问题，去掉同步接口是不可能的，所以要给阻塞的线程设置一个超时时间，当长时间没有等到模型的处理数据时，主动放弃监听，释放掉占用的资源，从而保证服务器资源充足；思考虽然问题解决了，但是模型的数据产出最长达10秒钟，当并发量过大时还是会出现这种问题，在不动模型的情况下如何解决这种问题？如何一直保证服务器资源充足？参考资料阻塞Map的实现：https://songsong.iteye.com/blog/802881压力测试简介和JMeter的简单实用：https://www.cnblogs.com/TankXiao/p/4059378.html","link":"/2019/08/1566309227978/"},{"title":"数组","text":"问题：为什么数组下标是从0开始，而不是从1开始；什么是数组？数组是一种线性表数据结构，它用一组连续的内存空间来存储一组相同类型的数据。线性表结构：数据排成一条线一样的结构，每个线性表上最多只有前和后两个方向，除数组外，链表、队列、栈也是线性结构。非线性结构：比如：二叉树、图、堆等，在非线性结构中，数据之间并不是简单的前后关系。连续的内存空间和相同类型的数据：正式因为这两个特性，才有了它的一大特性：“随机访问”；缺点：在数组中要进行删除或者插入操作需要进行大量的迁移工作，效率低下；关于数组的随机访问：例如一个长度为10的int类型的数组 int a[] = new int[10];在下图中，计算机给数组 a[10]分配了一块儿连续的内存空间 1000~1039；其中，内存的首地址 base_address=1000我们知道，计算机会给每一个内存单元分配一个地址，通过地址来访问到内存中存储的数据；当计算机需要随机访问数组中的元素时，会根据如下的公式找出该元素存储的内存地址：1a[i]_address = base_address + i * data_type_size其中 data_type_size表示数据中每个元素的大小。在当前例子中存储的为 int 类型，所以 data_type_size的大小为 4。“链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)”。这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。低效的插入和删除插入操作假设数组arr的长度为n，现在我们要在数组arr的第k个位置插入一个元素，为了把 k这个位置腾出来给新的元素，那么我们需要把 k~n这部分元素都顺序往后移一位。如果是插入到数组的末尾，那么我们就不需要对移动数据，这时候时间复杂度为O(1)。如果在数组的开头插入元素，那所有的数据都要往后移一位，这时候的时间复杂度为O(n)。那么平均复杂度则为O(n)。如果我们插入的元素是有序的，那么我们就必须按照上边的操作依次将数组往后移动一位。但是如果数组中的元素没有任何规律，数组只是被当做一个存储数据的集合。在这种情况下，如果想要将某个数据插入到k这个位置，为了避免大量的数据迁移，最简单的方法就是，直接将第k位的元素放到最后，把要插入的元素直接放到k的位置。例如：现有数组 a[10]存储了五个元素：a、b、c、d、e；我们现在要将元素x插入到第三个位置，我们只需要把c放到a[5]，将a[2]赋值为x即可；最终得到的数组中的元素为：a、b、x、d、e、c；利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。删除操作和插入操作类似，当我们要删除数组中的某个元素时，要对数据进行搬移操作，不然数据中间会出现空洞，内存就不连续了；和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？例如：数组 a[10] 中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素；为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。这是 JVM 标记清除垃圾回收算法的核心思想解题开篇现在我们来思考开篇的问题：为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也讲到，如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 data_type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：1a[k]_address = base_address + k * data_type_size但是，如果数组从 1 开始计数，那我们计算数组元素 a[k] 的内存地址就会变为：1a[k]_address = base_address + (k - 1) * data_type_size对比两个公式，我们不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。思考：JVM 的标记清除垃圾回收算法的核心理念。前面我提到一维数组的内存寻址公式，思考、类比一下，二维数组的内存寻址公式是怎样的呢？","link":"/2019/08/1566264829996/"},{"title":"基于Hexo&GitHub从零搭建个人博客","text":"现在越来越多的人喜欢利用Github搭建静态网站，原因不外乎简单省钱。本人也利用hexo+github搭建了本博客，用于分享一些心得。在此过程中，折腾博客的各种配置以及功能占具了我一部分时间，在此详细记录下我是如何利用hexo+github搭建静态博客以及一些配置相关问题，以免过后遗忘，且当备份之用。准备工作下载&amp;安装node.js，默认会安装npm：https://nodejs.org/zh-cn/下载&amp;安装git：https://git-scm.com/downloads下载安装hexo。方法：打开cmd 运行npm install -g hexo本地搭建hexo静态博客新建一个文件夹，如blog进入该文件夹内，右击运行git，输入：hexo init（生成hexo模板）生成完模板，运行npm install（目前貌似不用运行这一步）最后运行：hexo s （运行程序，访问本地localhost:4000可以看到博客已经搭建成功）目录介绍1234567891011121314├── _config.yml // 博客配置文件├── public // 静态文件存放目录│ ├── 2019│ ├── archives│ ├── css│ ├── images│ ├── index.html│ ├── js│ └── lib├── source │ └── _posts // 博文存放路径└── themes // 主题路径 ├── landscape └── next将博客与Github关联在Github上创建名字为XXX.github.io的项目，XXX为自己的GitHub用户名。打开本地的MyBlog文件夹项目内的_config.yml配置文件，将其中的type设置为git1234deploy: type: git repository: https://github.com/XXX/XXX.github.io.git branch: master运行：npm install hexo-deployer-git –save运行：hexo g（本地生成静态文件）运行：hexo d（将本地静态文件推送至Github）此时打开 https://XXX.github.io ，即可看到效果这里注意把文中的 XXX 修改为自己的github用户名更新文章在blog目录下执行：hexo new “我的第一篇文章”，会在source-&gt;_posts文件夹内生成一个.md文件。编辑该文件（遵循Markdown规则）修改起始字段title 文章的标题date 创建日期 （文件的创建日期 ）updated 修改日期 （ 文件的修改日期）comments 是否开启评论 truetags 标签categories 分类permalink url中的名字（文件名）编写正文内容（MakeDown）hexo clean 删除本地静态文件（public目录）hexo g 生成本地静态文件（public目录）hexo deploy 将本地静态文件推送至github（hexo d）修改主题至此，我们的博客就已经搭建完了，发现两个问题，一是丑，二是使用GitHub默认域名不舒服。所以我们要修改一个好看的主题（默认的主题经过一番DIY也能达到不错的效果，这里就不多做演示）和使用自己的域名（可选），非必须，看个人喜好。目前安装的主题：Next更多主题：主题主题配置文档：Next主题配置1、在博客的根目录下，也就是上文提到的blog文件夹中，执行clone主题1$ git clone https://github.com/theme-next/hexo-theme-next themes/next2、修改hexo配置文件使用文本编辑器打开blog目录下的_config.yml文件，将 themes 对应的值进行修改，如下：1theme: next3、重新生成静态文件12345$ hexo clean$ hexo g$ hexo s浏览器打开 http://localhost:4000 即可看到效果。确认没问题执行 hexo d 命令更新到GitHub，稍等片刻重新打开 https://XXX.github.io 便可看到效果；绑定域名域名提供商设置添加一条CNAME记录：CNAME —&gt; XXX.github.io博客添加CNAME文件配置完域名解析后，进入博客目录，在source目录下新建CNAME文件，写入域名，如：jacian.com运行：hexo g运行：hexo d重新发布完，稍等片刻打开自己的域名即可看到效果。至此你的个人博客就已经搭建完毕了；当然，你还可以做一些DIY的设置，在这篇文章中就不一一列举了，可以参考文档或者其他大神的博客去进行一些自定义的设置。","link":"/2019/08/1566205201987/"},{"title":"基于Netty-SocketIO的主动推送服务","text":"背景前端时间，公司开发了一款主动服务的机器人的程序，讲产生的消息通过服务端主动推送到客户端(H5、IOS、Android)，支持用户的个性化开关设置，用户可自由选择接受的消息类型；同时支持用户主动提问；在此记录下整个部署以及实现的大致思路；同时感谢我的Leader给予的帮助。部署Nginx配置为了保持长连接有效，配置HTTP版本1.1；配置Upgrade和Connection响应头信息；完整配置如下：12345678location / { proxy_pass http://nodes; # enable WebSockets proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\";}Socket配置Socket配置类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public class WebSocketConfig { private Logger log = LoggerFactory.getLogger(WebSocketConfig.class); @Value(\"${wss.server.host}\") private String host; @Value(\"${wss.server.port}\") private Integer port; @Value(\"${redis.passwd}\") private String redisPasswd; @Value(\"${redis.address}\") private String redisAddress; @Bean public PubSubStore pubSubStore() { return socketIOServer().getConfiguration().getStoreFactory().pubSubStore(); } @Bean public SocketIOServer socketIOServer() { Config redissonConfig = new Config(); // 高版本需求 redis:// 前缀 redissonConfig.useSingleServer().setPassword(\"xxx\").setAddress(\"redis://xxx:xx\").setDatabase(); RedissonClient redisson = Redisson.create(redissonConfig); RedissonStoreFactory redisStoreFactory = new RedissonStoreFactory(redisson); Configuration config = new Configuration(); config.setHostname(host); config.setPort(port); config.setOrigin(origin); config.setHttpCompression(false); config.setWebsocketCompression(false); config.setStoreFactory(redisStoreFactory); // 注意如果开放跨域设置，需要设置为null而不是\"*\" config.setOrigin(null); // 协议升级超时时间（毫秒），默认10000。HTTP握手升级为ws协议超时时间 config.setUpgradeTimeout(10000); // Ping消息间隔（毫秒），默认25000。客户端向服务器发送一条心跳消息间隔 config.setPingInterval(25000); // Ping消息超时时间（毫秒），默认60000，这个时间间隔内没有接收到心跳消息就会发送超时事件 config.setPingTimeout(60000); /** 异常监听事件，必须覆写全部方法 */ config.setExceptionListener(new ExceptionListener(){ @Override public void onConnectException(Exception e, SocketIOClient client) { ResponseMessage error = ResponseMessage.error(-1, \"连接异常！\"); client.sendEvent(\"exception\", JSON.toJSON(new Response&lt;String&gt;(error, \"连接异常！\"))); } @Override public void onDisconnectException(Exception e, SocketIOClient client) { ResponseMessage error = ResponseMessage.error(-1, \"断开异常！\"); client.sendEvent(\"exception\",JSON.toJSON(new Response&lt;String&gt;(error, \"连接异常！\"))); } @Override public void onEventException(Exception e, List&lt;Object&gt; data, SocketIOClient client) { ResponseMessage error = ResponseMessage.error(-1, \"服务器异常！\"); client.sendEvent(\"exception\",JSON.toJSON(new Response&lt;String&gt;(error, \"连接异常！\"))); } @Override public void onPingException(Exception e, SocketIOClient client) { ResponseMessage error = ResponseMessage.error(-1, \"PING 超时异常！\"); client.sendEvent(\"exception\",JSON.toJSON(new Response&lt;String&gt;(error, \"PING 超时异常！\"))); } @Override public boolean exceptionCaught(ChannelHandlerContext ctx, Throwable e) { return false; } }); // 类似于过滤器设置，此处不作处理 config.setAuthorizationListener(data -&gt; {// // 可以使用如下代码获取用户密码信息// String appId = data.getSingleUrlParam(\"appId\");// String source = data.getSingleUrlParam(\"source\");// log.info(\"token {}, client {}\", appId, source); return true; }); return new SocketIOServer(config); } @Bean public SpringAnnotationScanner springAnnotationScanner(SocketIOServer socketServer) { return new SpringAnnotationScanner(socketServer); }}Socket启动类12345678910111213141516171819@Log4j2@Component@Order(value=1)public class ServerRunner implements CommandLineRunner { private final SocketIOServer server; @Autowired public ServerRunner(SocketIOServer server) { this.server = server; } @Override public void run(String... args) throws Exception { server.start(); log.info(\"socket.io启动成功！\"); }}最终架构实现过程主动推送服务监听作为KafKa消费者，数据生产者讲加工好的数据推到KafKa中，消费者监听到消息广播给客户端；推送时在数据库查询用户对应的个性化设置，仅推送客户端选择接受的消息；由于主动推送服务部署了多个节点，而多个节点分配在同一个KafKa消费组中，这样会引起多个节点仅消费到全部消息的一部分的问题；这里使用Redis的发布/订阅的机制解决了这个问题：当各个节点消费到消息之后，将消息发布之后，其它节点订阅该Topic将消息发送给各自节点上连接的客户端，在这里各个节点即是发布者，又是订阅者；从数据的产生，到消费使用Redisson的Topic实现分布式发布/订阅Redisson为了方便Redis中的发布/订阅机制的使用，将其封装成Topic，并提供了代码级别的发布/订阅操作，如此一来多个JVM进程连接到Redis（单机/集群）后，便可以实现在一个JVM进程中发布的Topic，在其他已经订阅了该主题的JVM进程中就能及时收到消息。在Netty-SocketIO整合了Redisson之后，内部也使用了发布/订阅机制消息的发布123456789101112131415161718public void sendMessageToAllClient(String eventType, String message, String desc) { Collection&lt;SocketIOClient&gt; clients = server.getBroadcastOperations().getClients(); for(final SocketIOClient client : clients){ // Do Somthing } Packet packet = new Packet(PacketType.MESSAGE); packet.setData(new BroadcastMessage(message, eventType, desc)); publishMessage(packet);}private void publishMessage(Packet packet) { DispatchMessage dispatchMessage = new DispatchMessage(\"\", packet, \"\"); pubSubStore.publish(PubSubType.DISPATCH, dispatchMessage); BroadcastMessage broadcastMessage = dispatchMessage.getPacket().getData();}消息的订阅1234567891011@PostConstructpublic void init() { pubSubStore.subscribe(PubSubType.DISPATCH, dispatchMessage -&gt; { BroadcastMessage messageData = dispatchMessage.getPacket().getData(); Collection&lt;SocketIOClient&gt; clients = server.getBroadcastOperations().getClients(); for(final SocketIOClient client : clients){ // DO Somthing }, DispatchMessage.class);}","link":"/2019/07/1560849063604/"},{"title":"Joda Time使用小结","text":"一、Joda Time基础操作1、 构造指定时间12345678910111213// 明确给出年月日时分秒,同时还可以指定毫秒DateTime dateTime = new DateTime(2017,9,14,20,30,0); // 使用时间戳构造Datetime dateTime = new DateTime(1505371053358L);// 使用字符串构造，使用字符串构造需要自己定义patternString date = \"2017-09-14 20:30:00\";DateTimeFormatter dateTimeFormatter = DateTimeFormat.forPattern(\"yyyy-MM-dd HH:mm:ss\");DateTime dateTime = dateTimeFormatter.parseDateTime(date);// 指定时区构造时间DateTime dateTime = new DateTime(DateTimeZone.forTimeZone(TimeZone.getTimeZone(\"Asia/Shanghai\")));注意：”Asia/Shanghai”是国际时区Id，该ID可以通过JDK代码获取，代码如下：1234String[] zones = TimeZone.getAvailableIDs();for (String zone : zones) { System.out.println(zone);}2、获取当前时间的时间戳1234// JDKlong currentTimeOfMills = System.currentTimeMillis();// Joda Timelong currentTimeOfMills = DateTime.now().getMillis();3、获得当前时间的时区1DateTimeZone zone = DateTime.now().getZone();4、 获取指定时区的当前时间12DateTimeZone gmt = DateTimeZone.forID(\"GMT\");DateTime dateTime = DateTime.now().toDateTime(gmt);二、Joda Time 对年月日的一些简单操作。1、 获取月初第一天和月末最后一天12345678910111213141516171819DateTime dateTime = new DateTime();// 月初第一天DateTime theFirstDateOfMonth = dateTime.dayOfMonth().withMinimumValue();// 当前月最后一天DataTime theEndDataOfMonth = dateTime.dayOfMonth().withMaximumValue();// 这一天是几号int day = dateTime.getDayOfMonth();// 这一天是哪月int month = dateTime.getMothOfYear();// 这一天是哪年int year = dateTime.getYear();// 判断本月是不是9月if(dateTime.getDayOfMonth() == DateTimeConstants.SEPTEMBER){//TODO}// 获取相对于当前时间的月份，比如获取上个月的时间或者下个月的是时间，方法minusMoths接受一个int的参数，如果这个参数等于0，代表本月，大于0代表已经过去的时间，小于0代表还没有到来的时间 LocalDate lastDayOfMonth = new LocalDate().minusMonths(1).dayOfMonth().withMaximumValue();2、关于星期的操作1234567DateTime dateTime = new DateTime();// 今天是星期几int week = dateTime.getDayOfWeek();// 判断今天是不是星期三if(dateTime.getDayOfWeek() == DateTimeConstants.WEDNESDAY){ // TODO}注意：DateTimeConstants中包含了许多你需要的常量，而不用你自己去定义，比如星期、月份、上午还是下午都有哦3、计算时间差注意开始时间与结束时间参数位置，如果开始时间小于结束时间，得到的天数是正数，否则就是负数哦！1234567891011121314151617DateTime currentDateTime = new DateTime();DateTime targetDateTime = new DateTime(2017,10,1,0,0,0);// 相差多少年int years = Years.yearsBetween(currentDateTime,targetDateTime).getYears();// 相差多少月int months = Months.monthsBetween(currentDateTime,targetDateTime).getMonths();// 距离国庆放假还有多少天，嘎嘎！int days = Days.daysBetween(currentDateTime,targetDateTime).getDays();// 相差多少小时int hours = Hours.hoursBetween(currentDateTime,targetDateTime).getHours();// 相差多少分钟int minutes = Minutes.minutesBetween(currentDateTime,targetDateTime).getMinutes();// 相差多少秒int seconds = Seconds.secondsBetween(currentDateTime,targetDateTime).getSeconds();// 相差多少周int weeks = Weeks.weeksBetween(currentDateTime,targetDateTime).getWeeks();4、获取零点相关的时间123456789101112131415DateTime currentDateTime = new DateTime();// 今天的零点DateTime dateTime = currentDateTime.withMillisOfDay(0)；// 昨天的零点DateTime dateTime = currentDateTime.withMillisOfDay(0).plusDays(-1);// 明天的零点DateTime dateTime = currentDateTime.withMillisOfDay(0).plusDays(1);// 这一年最后一天0点new DateTime().dayOfYear().withMaximumValue().withMillisOfDay(0)// 这一年第一天0点new DateTime().dayOfYear().withMinimumValue().withMillisOfDay(0)// 这个月最后一天0点new DateTime().dayOfMonth().withMaximumValue().withMillisOfDay(0)// 这个月月初0点new DateTime().dayOfMonth().withMinimumValue().withMillisOfDay(0)注意：要获取多少天后或者多少天前的零点，只需在plusDays()方法中填写相应参数即可三、准确使用Joda Time的时间处理类1、格式化就这么简单12345678910111213// 格式化时间DateTime currentDateTime = new DateTime();currentDateTime.toString(\"yyyy-MM-dd HH:mm:ss\");// 指定时区格式化String format = \"yyyy-MM-dd HH:mm:ss\";DateTime dateTime = new DateTime();dateTime.toString(format, Locale.US);// 格式化时分秒（单位毫秒并且最大可格式23:59:59，超出将报错）int millis = 120000;LocalTime localTime = new LocalTime().withMillisOfDay(millis);localTime.toString(\"HH:mm:ss\");2、 如果业务只需要日期，请使用LocalDate,因为LocalDate仅仅关心日期，更专业，也减少了不必要的资源消耗；如果业务只关心时间，那么使用LocalTime。例如：123456LocalDate localDate = new LocalDate();LocalTime localTime = new LocalTime();System.out.println(localDate);// 2017-09-14System.out.println(localTime);//10:54:14.5063、 如果业务需要日期时间都要使用，那么可以使用LocalDateTime, DateTime这两个类，它们都是线程安全的同时都是不可变的，使用起来不用担心出问题。LocalDateTime是与时区无关的。DateTime是与时区相关的一个国际标准时间。使用的时候根据自己的需要选择，详细的解释看官方文档吧！4、再次提醒要使用DateTimeConstants类定义好的常量，避免重复造轮子。下面给出DateTimeConstants类的常量（也不多），不在解释，望名知义。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 月份public static final int JANUARY = 1;public static final int FEBRUARY = 2;public static final int MARCH = 3;public static final int APRIL = 4;public static final int MAY = 5;public static final int JUNE = 6;public static final int JULY = 7;public static final int AUGUST = 8;public static final int SEPTEMBER = 9;public static final int OCTOBER = 10;public static final int NOVEMBER = 11;public static final int DECEMBER = 12;// 星期public static final int MONDAY = 1;public static final int TUESDAY = 2;public static final int WEDNESDAY = 3;public static final int THURSDAY = 4;public static final int FRIDAY = 5;public static final int SATURDAY = 6;public static final int SUNDAY = 7;// 上午&amp;下午public static final int AM = 0;public static final int PM = 1;// 公元前...年(基督之前...年)public static final int BC = 0;// 公元前public static final int BCE = 0;// 公元...年(原义为主的纪年)public static final int AD = 1;// 基督纪元,公元public static final int CE = 1;// 1秒对应毫秒数public static final int MILLIS_PER_SECOND = 1000;// 1分钟对应秒数public static final int SECONDS_PER_MINUTE = 60;// 1分钟对应毫秒数public static final int MILLIS_PER_MINUTE = 60000;// 1小时对应分钟数public static final int MINUTES_PER_HOUR = 60;// 1小时对应的秒数public static final int SECONDS_PER_HOUR = 3600;// 1小时对应的毫秒数public static final int MILLIS_PER_HOUR = 3600000;// 1天对应的小时public static final int HOURS_PER_DAY = 24;// 1天对应的分钟数public static final int MINUTES_PER_DAY = 1440;// 1天对应的秒数public static final int SECONDS_PER_DAY = 86400;// 1天对应的毫秒数public static final int MILLIS_PER_DAY = 86400000;// 1周对应的天数public static final int DAYS_PER_WEEK = 7;// 1周对应的小时public static final int HOURS_PER_WEEK = 168;// 1周对应的分钟public static final int MINUTES_PER_WEEK = 10080;// 1周对应的秒数public static final int SECONDS_PER_WEEK = 604800;// 1周对应的毫秒数public static final int MILLIS_PER_WEEK = 604800000;","link":"/2019/06/1560418746556/"},{"title":"SpringBoot-Feign使用","text":"123SpringBoot：2.1.5.RELEASEFeign：2.0.1.RELEASEfeign-okHttp：9.7.0Feign 简介Spring Cloud的Feign支持的一个中心概念就是命名客户端.Feign客户端使用@FeignClient注册组合成组件,按需调用远程服务器.Spring Cloud使用FeignClientsConfiguration创建一个新的集合作为每个命名客户端的ApplicationContext(应用上下文), 包含feign.Decoder，feign.Encoder和feign.Contract.你可以使用 Jersey 和 CXF 这些来写一个 Rest 或 SOAP 服务的java客服端。你也可以直接使用 Apache HttpClient 来实现。但是 Feign 的目的是尽量的减少资源和代码来实现和 HTTP API 的连接。通过自定义的编码解码器以及错误处理，你可以编写任何基于文本的 HTTP API。Feign 通过注解注入一个模板化请求进行工作。只需在发送之前关闭它，参数就可以被直接的运用到模板中。然而这也限制了 Feign，只支持文本形式的API，它在响应请求等方面极大的简化了系统。同时，它也是十分容易进行单元测试的。Spring Cloud应用在启动时，Feign会扫描标有@FeignClient注解的接口，生成代理，并注册到Spring容器中。生成代理时Feign会为每个接口方法创建一个RequetTemplate对象，该对象封装了HTTP请求需要的全部信息，请求参数名、请求方法等信息都是在这个过程中确定的，Feign的模板化就体现在这里。Maven依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/dependency&gt;Feign客户端接口(调用方)12345678@FeignClient(name = \"testDemo\", url = \"localhost:8080/student\")public interface TestFeignRepository { @GetMapping String get1(); @PostMapping String get2();}启动类添加@EnableFeignClients注解123456789@SpringBootApplication@EnableFeignClientspublic class TestprojectApplication { public static void main(String[] args) { SpringApplication.run(TestprojectApplication.class, args); }}@FeignClient注解参数name：指定FeignClient的名称，如果项目使用了Ribbon，name属性会作为微服务的名称，用于服务发现url: url一般用于调试，可以手动指定@FeignClient调用的地址decode404:当发生http 404错误时，如果该字段位true，会调用decoder进行解码，否则抛出FeignExceptionconfiguration: Feign配置类，可以自定义Feign的Encoder、Decoder、LogLevel、Contractfallback: 定义容错的处理类，当调用远程接口失败或超时时，会调用对应接口的容错逻辑，fallback指定的类必须实现@FeignClient标记的接口fallbackFactory: 工厂类，用于生成fallback类示例，通过这个属性我们可以实现每个接口通用的容错逻辑，减少重复的代码path: 定义当前FeignClient的统一前缀Feign使用OkHttp3和HystrixMaven依赖12345678910&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt; &lt;version&gt;9.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-hystrix&lt;/artifactId&gt; &lt;version&gt;9.7.0&lt;/version&gt;&lt;/dependency&gt;配置文件：application.yml1234567feign: httpClient: enabled: false okhttp: enabled: true hystrix: enabled: true配置类12345678910111213141516@Configuration@ConditionalOnClass(Feign.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignOkHttpConfig { @Bean public okhttp3.OkHttpClient okHttpClient(){ return new okhttp3.OkHttpClient.Builder() .readTimeout(60, TimeUnit.SECONDS) .connectTimeout(60, TimeUnit.SECONDS) .writeTimeout(120, TimeUnit.SECONDS) .connectionPool(new ConnectionPool())// .addInterceptor() // 拦截器 .build(); }}","link":"/2019/05/1558667840825/"},{"title":"WebSocket主动推送服务","text":"服务器与Web页面交互方式传统的 Web 服务都是客户端发出请求，服务端给出响应。HTTPHTTP短连接：在HTTP1.0中，客户端发送请求，服务器接收请求， 双⽅建⽴连接，服务器响应资源，请求结束。HTTP⻓连接：在HTTP 1.1中，客户端发出请求，服务端接收请 求，双⽅建⽴连接，在服务端没有返回之前保持连接，当客户端再 发送请求时，它会使⽤同⼀个连接。这⼀直继续到客户端或服务器 端认为会话已经结束，其中⼀⽅中断连接。服务器向 Web 页面推送消息的方式非阻塞轮询（短轮询）：客户端以固定的频率（比如10秒钟一次）向服务端发送请求，如果服务端没有数据响应，就直接响应一个空，如果有数据响应，就将响应数据作为结果返回给客户端。特点是每次请求后，都会立即给响应。阻塞长轮询（长轮询）：客户端像传统轮询一样从服务器请求数据。如果服务器没有可以立即返回给客户端的数据，则不会立刻返回一个空结果，而是保持这个请求等待数据到来（请求阻塞或者超时），等有响应数据之后将数据作为结果返回给客户端。特点是一次请求后直到有响应数据时才会给返回，否则阻塞等待。短轮询优点是实现逻辑简单，但是当间隔太短时，会有⼤量的请求发送到 服务器，会对服务器负载造成影响；⽽间隔太⻓，业务数据的实时 性得不到保证⽆效请求的数量多。在⽤户量较⼤的情况下，服务器 负载较⾼。⻓轮询优点是消息实时性⾼，⽆消息的情况下不会进⾏频繁的请求；缺点 是服务端维持和客户端的连接会消耗掉⼀部分资源。WebSocketWebSocket 是 HTML5 ⼀种新的协议（Web TCP）。它建⽴ 在 TCP 之上，实现了客户端和服务端全双⼯异步通信.它和 HTTP 最⼤不同是：WebSocket 是⼀种双向通信协议，WebSocket 服务器和 Browser/ Client Agent 都能主动的向对⽅发送或接收数据；WebSocket 需要类似 TCP 的客户端和服务器端通过握⼿连接，连 接成功后才能相互通信。服务端与客户端通信架构加⼯后的数据经过 KAFKA 推送到 WEBSOCKET 的消费端数据流（从⽣产数据到⽤户端展⽰）","link":"/2019/05/1558580640500/"},{"title":"Spring Boot中使用@Async实现异步调用","text":"什么是“异步调用”？“异步调用”对应的是“同步调用”，同步调用指程序按照定义顺序依次执行，每一行程序都必须等待上一行程序执行完成之后才能执行；异步调用指程序在顺序执行时，不等待异步调用的语句返回结果就执行后面的程序。同步调用下面通过一个简单示例来直观的理解什么是同步调用：定义Task类，创建三个处理函数分别模拟三个执行任务的操作，操作消耗时间随机取（10秒内）123456789101112131415161718192021222324252627282930@Componentpublic class Task { public static Random random =new Random(); public void doTaskOne() throws Exception { System.out.println(&quot;开始做任务一&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(&quot;完成任务一，耗时：&quot; + (end - start) + &quot;毫秒&quot;); } public void doTaskTwo() throws Exception { System.out.println(&quot;开始做任务二&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(&quot;完成任务二，耗时：&quot; + (end - start) + &quot;毫秒&quot;); } public void doTaskThree() throws Exception { System.out.println(&quot;开始做任务三&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(&quot;完成任务三，耗时：&quot; + (end - start) + &quot;毫秒&quot;); }}在单元测试用例中，注入Task对象，并在测试用例中执行doTaskOne、doTaskTwo、doTaskThree三个函数。123456789101112131415@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = Application.class)public class ApplicationTests { @Autowired private Task task; @Test public void test() throws Exception { task.doTaskOne(); task.doTaskTwo(); task.doTaskThree(); }}执行单元测试，可以看到类似如下输出：123456开始做任务一完成任务一，耗时：4256毫秒开始做任务二完成任务二，耗时：4957毫秒开始做任务三完成任务三，耗时：7173毫秒任务一、任务二、任务三顺序的执行完了，换言之doTaskOne、doTaskTwo、doTaskThree三个函数顺序的执行完成。异步调用上述的同步调用虽然顺利的执行完了三个任务，但是可以看到执行时间比较长，若这三个任务本身之间不存在依赖关系，可以并发执行的话，同步调用在执行效率方面就比较差，可以考虑通过异步调用的方式来并发执行。在Spring Boot中，我们只需要通过使用@Async注解就能简单的将原来的同步函数变为异步函数，Task类改在为如下模式：12345678910111213141516171819@Componentpublic class Task { @Async public void doTaskOne() throws Exception { // 同上内容，省略 } @Async public void doTaskTwo() throws Exception { // 同上内容，省略 } @Async public void doTaskThree() throws Exception { // 同上内容，省略 }}为了让@Async注解能够生效，还需要在Spring Boot的主程序中配置@EnableAsync，如下所示：123456789@SpringBootApplication@EnableAsyncpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }}此时可以反复执行单元测试，您可能会遇到各种不同的结果，比如：没有任何任务相关的输出有部分任务相关的输出乱序的任务相关的输出原因是目前doTaskOne、doTaskTwo、doTaskThree三个函数的时候已经是异步执行了。主程序在异步调用之后，主程序并不会理会这三个函数是否执行完成了，由于没有其他需要执行的内容，所以程序就自动结束了，导致了不完整或是没有输出任务相关内容的情况。注： @Async所修饰的函数不要定义为static类型，这样异步调用不会生效异步回调为了让doTaskOne、doTaskTwo、doTaskThree能正常结束，假设我们需要统计一下三个任务并发执行共耗时多少，这就需要等到上述三个函数都完成调动之后记录时间，并计算结果。那么我们如何判断上述三个异步调用是否已经执行完成呢？我们需要使用Future&lt;T&gt;来返回异步调用的结果，就像如下方式改造doTaskOne函数：123456789@Asyncpublic Future&lt;String&gt; doTaskOne() throws Exception { System.out.println(&quot;开始做任务一&quot;); long start = System.currentTimeMillis(); Thread.sleep(random.nextInt(10000)); long end = System.currentTimeMillis(); System.out.println(&quot;完成任务一，耗时：&quot; + (end - start) + &quot;毫秒&quot;); return new AsyncResult&lt;&gt;(&quot;任务一完成&quot;);}按照如上方式改造一下其他两个异步函数之后，下面我们改造一下测试用例，让测试在等待完成三个异步调用之后来做一些其他事情。12345678910111213141516171819202122@Testpublic void test() throws Exception { long start = System.currentTimeMillis(); Future&lt;String&gt; task1 = task.doTaskOne(); Future&lt;String&gt; task2 = task.doTaskTwo(); Future&lt;String&gt; task3 = task.doTaskThree(); while(true) { if(task1.isDone() &amp;&amp; task2.isDone() &amp;&amp; task3.isDone()) { // 三个任务都调用完成，退出循环等待 break; } Thread.sleep(1000); } long end = System.currentTimeMillis(); System.out.println(&quot;任务全部完成，总耗时：&quot; + (end - start) + &quot;毫秒&quot;);}看看我们做了哪些改变：在测试用例一开始记录开始时间在调用三个异步函数的时候，返回Future&lt;String&gt;类型的结果对象在调用完三个异步函数之后，开启一个循环，根据返回的Future&lt;String&gt;对象来判断三个异步函数是否都结束了。若都结束，就结束循环；若没有都结束，就等1秒后再判断。跳出循环之后，根据结束时间 - 开始时间，计算出三个任务并发执行的总耗时。执行一下上述的单元测试，可以看到如下结果：1234567开始做任务一开始做任务二开始做任务三完成任务三，耗时：37毫秒完成任务二，耗时：3661毫秒完成任务一，耗时：7149毫秒任务全部完成，总耗时：8025毫秒可以看到，通过异步调用，让任务一、二、三并发执行，有效的减少了程序的总运行时间。代码示例本文的相关例子可以查看下面仓库中的chapter4-1-2目录：github: https://github.com/WuliGitH/SpringBoot-Learning-1文章转自 “程序猿DD” 博客 ,","link":"/2019/05/1557024737335/"},{"title":"SpringBoot中使用@Scheduled创建定时任务","text":"我们在编写Spring Boot应用中经常会遇到这样的场景，比如：我需要定时地发送一些短信、邮件之类的操作，也可能会定时地检查和监控一些标志、参数等。创建定时任务在Spring Boot中编写定时任务是非常简单的事，下面通过实例介绍如何在Spring Boot中创建定时任务，实现每过5秒输出一下当前时间。在Spring Boot的主类中加入@EnableScheduling注解，启用定时任务的配置123456789@SpringBootApplication@EnableSchedulingpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }}创建定时任务实现类1234567891011@Componentpublic class ScheduledTasks { private static final SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;HH:mm:ss&quot;); @Scheduled(fixedRate = 5000) public void reportCurrentTime() { System.out.println(&quot;现在时间：&quot; + dateFormat.format(new Date())); }}运行程序，控制台中可以看到类似如下输出，定时任务开始正常运作了。12345672016-05-15 10:40:04.073 INFO 1688 --- [ main] com.didispace.Application : Started Application in 1.433 seconds (JVM running for 1.967)现在时间：10:40:09现在时间：10:40:14现在时间：10:40:19现在时间：10:40:24现在时间：10:40:29522现在时间：10:40:34关于上述的简单入门示例也可以参见官方的Scheduling Tasks@Scheduled详解在上面的入门例子中，使用了@Scheduled(fixedRate = 5000) 注解来定义每过5秒执行的任务，对于@Scheduled的使用可以总结如下几种方式：@Scheduled(fixedRate = 5000) ：上一次开始执行时间点之后5秒再执行@Scheduled(fixedDelay = 5000) ：上一次执行完毕时间点之后5秒再执行@Scheduled(initialDelay=1000, fixedRate=5000) ：第一次延迟1秒后执行，之后按fixedRate的规则每5秒执行一次@Scheduled(cron=&quot;*/5 * * * * *&quot;) ：通过cron表达式定义规则代码示例本文的相关例子可以查看下面仓库中的chapter4-1-1目录：github: https://github.com/WuliGitH/SpringBoot-Learning-1文章转自 “程序猿DD” 博客 ,","link":"/2019/04/1554167003980/"},{"title":"Spring Boot属性配置文件详解","text":"相信很多人选择Spring Boot主要是考虑到它既能兼顾Spring的强大功能，还能实现快速开发的便捷。我们在Spring Boot使用过程中，最直观的感受就是没有了原来自己整合Spring应用时繁多的XML配置内容，替代它的是在pom.xml中引入模块化的Starter POMs，其中各个模块都有自己的默认配置，所以如果不是特殊应用场景，就只需要在application.properties中完成一些属性配置就能开启各模块的应用。在之前的各篇文章中都有提及关于application.properties的使用，主要用来配置数据库连接、日志相关配置等。除了这些配置内容之外，本文将具体介绍一些在application.properties配置中的其他特性和使用方法。自定义属性与加载我们在使用Spring Boot的时候，通常也需要定义一些自己使用的属性，我们可以如下方式直接定义：12com.didispace.blog.name=WuliGitcom.didispace.blog.title=Spring Boot教程然后通过@Value(&quot;${属性名}&quot;)注解来加载对应的配置属性，具体如下：1234567891011@Componentpublic class BlogProperties { @Value(&quot;${com.didispace.blog.name}&quot;) private String name; @Value(&quot;${com.didispace.blog.title}&quot;) private String title; // 省略getter和setter}按照惯例，通过单元测试来验证BlogProperties中的属性是否已经根据配置文件加载了。123456789101112131415@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(Application.class)public class ApplicationTests { @Autowired private BlogProperties blogProperties; @Test public void getHello() throws Exception { Assert.assertEquals(blogProperties.getName(), &quot;WuliGit&quot;); Assert.assertEquals(blogProperties.getTitle(), &quot;Spring Boot教程&quot;); }}参数间的引用在application.properties中的各个参数之间也可以直接引用来使用，就像下面的设置：123com.didispace.blog.name=WuliGitcom.didispace.blog.title=Spring Boot教程com.didispace.blog.desc=${com.didispace.blog.name}正在努力写《${com.didispace.blog.title}》com.didispace.blog.desc参数引用了上文中定义的name和title属性，最后该属性的值就是WuliGit正在努力写《Spring Boot教程》。使用随机数在一些情况下，有些参数我们需要希望它不是一个固定的值，比如密钥、服务端口等。Spring Boot的属性配置文件中可以通过${random}来产生int值、long值或者string字符串，来支持属性的随机值。12345678910# 随机字符串com.didispace.blog.value=${random.value}# 随机intcom.didispace.blog.number=${random.int}# 随机longcom.didispace.blog.bignumber=${random.long}# 10以内的随机数com.didispace.blog.test1=${random.int(10)}# 10-20的随机数com.didispace.blog.test2=${random.int[10,20]}通过命令行设置属性值相信使用过一段时间Spring Boot的用户，一定知道这条命令：java -jar xxx.jar --server.port=8888，通过使用–server.port属性来设置xxx.jar应用的端口为8888。在命令行运行时，连续的两个减号--就是对application.properties中的属性值进行赋值的标识。所以，java -jar xxx.jar --server.port=8888命令，等价于我们在application.properties中添加属性server.port=8888，该设置在样例工程中可见，读者可通过删除该值或使用命令行来设置该值来验证。通过命令行来修改属性值固然提供了不错的便利性，但是通过命令行就能更改应用运行的参数，那岂不是很不安全？是的，所以Spring Boot也贴心的提供了屏蔽命令行访问属性的设置，只需要这句设置就能屏蔽：SpringApplication.setAddCommandLineProperties(false)。多环境配置我们在开发Spring Boot应用时，通常同一套程序会被应用和安装到几个不同的环境，比如：开发、测试、生产等。其中每个环境的数据库地址、服务器端口等等配置都会不同，如果在为不同环境打包时都要频繁修改配置文件的话，那必将是个非常繁琐且容易发生错误的事。对于多环境的配置，各种项目构建工具或是框架的基本思路是一致的，通过配置多份不同环境的配置文件，再通过打包命令指定需要打包的内容之后进行区分打包，Spring Boot也不例外，或者说更加简单。在Spring Boot中多环境配置文件名需要满足application-{profile}.properties的格式，其中{profile}对应你的环境标识，比如：application-dev.properties：开发环境application-test.properties：测试环境application-prod.properties：生产环境至于哪个具体的配置文件会被加载，需要在application.properties文件中通过spring.profiles.active属性来设置，其值对应{profile}值。如：spring.profiles.active=test就会加载application-test.properties配置文件内容下面，以不同环境配置不同的服务端口为例，进行样例实验。针对各环境新建不同的配置文件application-dev.properties、application-test.properties、application-prod.properties在这三个文件均都设置不同的server.port属性，如：dev环境设置为1111，test环境设置为2222，prod环境设置为3333application.properties中设置spring.profiles.active=dev，就是说默认以dev环境设置测试不同配置的加载执行java -jar xxx.jar，可以观察到服务端口被设置为1111，也就是默认的开发环境（dev）执行java -jar xxx.jar --spring.profiles.active=test，可以观察到服务端口被设置为2222，也就是测试环境的配置（test）执行java -jar xxx.jar --spring.profiles.active=prod，可以观察到服务端口被设置为3333，也就是生产环境的配置（prod）按照上面的实验，可以如下总结多环境的配置思路：application.properties中配置通用内容，并设置spring.profiles.active=dev，以开发环境为默认配置application-{profile}.properties中配置各个环境不同的内容通过命令行方式去激活不同环境的配置完整示例chapter2-1-1文章转自 “程序猿DD” 博客 ,","link":"/2019/03/1553742366000/"},{"title":"SpringBoot中Web应用的统一异常处理","text":"我们在做Web应用的时候，请求处理过程中发生错误是非常常见的情况。Spring Boot提供了一个默认的映射：/error，当处理中抛出异常之后，会转到该请求中处理，并且该请求有一个全局的错误页面用来展示异常内容。选择一个之前实现过的Web应用（Chapter3-1-2）为基础，启动该应用，访问一个不存在的URL，或是修改处理内容，直接抛出异常，如：1234@RequestMapping(&quot;/hello&quot;)public String hello() throws Exception { throw new Exception(&quot;发生错误&quot;);}此时，可以看到类似下面的报错页面，该页面就是Spring Boot提供的默认error映射页面。统一异常处理虽然，Spring Boot中实现了默认的error映射，但是在实际应用中，上面你的错误页面对用户来说并不够友好，我们通常需要去实现我们自己的异常提示。下面我们以之前的Web应用例子为基础（Chapter3-1-2），进行统一异常处理的改造。创建全局异常处理类：通过使用@ControllerAdvice定义统一的异常处理类，而不是在每个Controller中逐个定义。@ExceptionHandler用来定义函数针对的异常类型，最后将Exception对象和请求URL映射到error.html中123456789101112131415@ControllerAdviceclass GlobalExceptionHandler { public static final String DEFAULT_ERROR_VIEW = &quot;error&quot;; @ExceptionHandler(value = Exception.class) public ModelAndView defaultErrorHandler(HttpServletRequest req, Exception e) throws Exception { ModelAndView mav = new ModelAndView(); mav.addObject(&quot;exception&quot;, e); mav.addObject(&quot;url&quot;, req.getRequestURL()); mav.setViewName(DEFAULT_ERROR_VIEW); return mav; }}实现error.html页面展示：在templates目录下创建error.html，将请求的URL和Exception对象的message输出。123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang=&quot;en&quot;&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;统一异常处理&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Error Handler&lt;/h1&gt; &lt;div th:text=&quot;${url}&quot;&gt;&lt;/div&gt; &lt;div th:text=&quot;${exception.message}&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;启动该应用，访问：http://localhost:8080/hello，可以看到如下错误提示页面。通过实现上述内容之后，我们只需要在Controller中抛出Exception，当然我们可能会有多种不同的Exception。然后在@ControllerAdvice类中，根据抛出的具体Exception类型匹配@ExceptionHandler中配置的异常类型来匹配错误映射和处理。返回JSON格式在上述例子中，通过@ControllerAdvice统一定义不同Exception映射到不同错误处理页面。而当我们要实现RESTful API时，返回的错误是JSON格式的数据，而不是HTML页面，这时候我们也能轻松支持。本质上，只需在@ExceptionHandler之后加入@ResponseBody，就能让处理函数return的内容转换为JSON格式。下面以一个具体示例来实现返回JSON格式的异常处理。创建统一的JSON返回对象，code：消息类型，message：消息内容，url：请求的url，data：请求返回的数据12345678910111213public class ErrorInfo&lt;T&gt; { public static final Integer OK = 0; public static final Integer ERROR = 100; private Integer code; private String message; private String url; private T data; // 省略getter和setter}创建一个自定义异常，用来实验捕获该异常，并返回json1234567public class MyException extends Exception { public MyException(String message) { super(message); }}Controller中增加json映射，抛出MyException异常123456789@Controllerpublic class HelloController { @RequestMapping(&quot;/json&quot;) public String json() throws MyException { throw new MyException(&quot;发生错误2&quot;); }}为MyException异常创建对应的处理123456789101112131415@ControllerAdvicepublic class GlobalExceptionHandler { @ExceptionHandler(value = MyException.class) @ResponseBody public ErrorInfo&lt;String&gt; jsonErrorHandler(HttpServletRequest req, MyException e) throws Exception { ErrorInfo&lt;String&gt; r = new ErrorInfo&lt;&gt;(); r.setMessage(e.getMessage()); r.setCode(ErrorInfo.ERROR); r.setData(&quot;Some Data&quot;); r.setUrl(req.getRequestURL().toString()); return r; }}启动应用，访问：http://localhost:8080/json，可以得到如下返回内容：123456{ code: 100， data: &quot;Some Data&quot;， message: &quot;发生错误2&quot;， url: &quot;http://localhost:8080/json&quot;}至此，已完成在Spring Boot中创建统一的异常处理，实际实现还是依靠Spring MVC的注解，更多更深入的使用可参考Spring MVC的文档。代码示例本文的相关例子可以查看下面仓库中的chapter3-1-6目录：Github：https://github.com/WuliGitH/SpringBoot-Learning-1文章转自 “程序猿DD” 博客 ,","link":"/2019/03/1553662122000/"},{"title":"CentOS7安装MySQL","text":"下载 repo 源进入 https://repo.mysql.com/ ，里面包含了所有可用的 MySQL 源。选择一个合适的版本，进行下载：1# wget https://repo.mysql.com/mysql57-community-release-el7.rpm如果提示-bash: wget: 未找到命令 执行以下命令, 安装wget:12&gt;# yum -y install wget&gt;完成之后，进行安装：1# rpm -ivh mysql57-community-release-el7.rpm安装MySQL开始安装MySQL123# yum install mysql -y# yum install mysql-server -y# yum install mysql-devel -yMySQL 是MySQL客户端MySQL-server 是数据库服务器MySQL-devel 包含了开发用到的库以及头文件到此为止MySQL就安装完成了。启动/停止 MySQL启动MySQL1# systemctl start mysqld.service查看MySQL运行状态1# systemctl status mysqld.service这就说明MySQL成功运行了。停止MySQL1# systemctl stop mysqld.service重启MySQL1# systemctl restart mysqld.service登陆MySQL通过查看日志获取初始密码1# grep \"password\" /var/log/mysqld.log输入以下命令并输入初始密码进入数据库1# mysql -uroot -p此时不能做任何事, 要将初始密码修改掉之后才可以进行操作。修改初始密码修改密码可以使用以下命令1mysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;new password&apos;;当我们输入的密码过于简单的时候会出现错误, 那是因为MySQL有相应的密码校验, 要求由大小写字母数字特殊符号组成, 否则无法完成修改 ; 如果仅用于自己测试, 想设置一个简单的密码可以参考下列操作 ;设置简单密码1234567891011121314151617181920212223# 修改MySQL参数配置mysql&gt; set global validate_password_policy=0;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global validate_password_mixed_case_count=0;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global validate_password_number_count=3;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global validate_password_special_char_count=0;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global validate_password_length=3;Query OK, 0 rows affected (0.00 sec)# 设置简单密码mysql&gt; SET PASSWORD FOR &apos;root&apos;@&apos;localhost&apos; = PASSWORD(&apos;root&apos;);Query OK, 0 rows affected, 1 warning (0.01 sec)# 刷新权限mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)OK，大功告成。设置允许远程访问MySQL允许任何主机连接12mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;password&apos; WITH GRANT OPTION;mysql&gt; flush privileges;允许指定IP连接12mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;jack&apos;@’10.10.50.127’ IDENTIFIED BY &apos;654321&apos; WITH GRANT OPTION;mysql&gt; flush privileges;如果远程连接出现错误请检查是否关闭防火墙。","link":"/2019/03/1553478546000/"},{"title":"SpringBoot中使用MongoDB数据库","text":"前段时间分享了关于Spring Boot中使用Redis的文章，除了Redis之后，我们在互联网产品中还经常会用到另外一款著名的NoSQL数据库MongoDB。下面就来简单介绍一下MongoDB，并且通过一个例子来介绍Spring Boot中对MongoDB访问的配置和使用。MongoDB简介MongoDB是一个基于分布式文件存储的数据库，它是一个介于关系数据库和非关系数据库之间的产品，其主要目标是在键/值存储方式（提供了高性能和高度伸缩性）和传统的RDBMS系统（具有丰富的功能）之间架起一座桥梁，它集两者的优势于一身。MongoDB支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型，也因为他的存储格式也使得它所存储的数据在Nodejs程序应用中使用非常流畅。既然称为NoSQL数据库，Mongo的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。但是，MongoDB也不是万能的，同MySQL等关系型数据库相比，它们在针对不同的数据类型和事务要求上都存在自己独特的优势。在数据存储的选择中，坚持多样化原则，选择更好更经济的方式，而不是自上而下的统一化。较常见的，我们可以直接用MongoDB来存储键值对类型的数据，如：验证码、Session等；由于MongoDB的横向扩展能力，也可以用来存储数据规模会在未来变的非常巨大的数据，如：日志、评论等；由于MongoDB存储数据的弱类型，也可以用来存储一些多变json数据，如：与外系统交互时经常变化的JSON报文。而对于一些对数据有复杂的高事务性要求的操作，如：账户交易等就不适合使用MongoDB来存储。MongoDB官网访问MongoDB在Spring Boot中，对如此受欢迎的MongoDB，同样提供了自配置功能。引入依赖Spring Boot中可以通过在pom.xml中加入spring-boot-starter-data-mongodb引入对mongodb的访问支持依赖。它的实现依赖spring-data-mongodb。是的，您没有看错，又是spring-data的子项目，之前介绍过spring-data-jpa、spring-data-redis，对于mongodb的访问，spring-data也提供了强大的支持，下面就开始动手试试吧。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt;快速开始使用Spring-data-mongodb若MongoDB的安装配置采用默认端口，那么在自动配置的情况下，我们不需要做任何参数配置，就能马上连接上本地的MongoDB。下面直接使用spring-data-mongodb来尝试对mongodb的存取操作。（记得mongod启动您的mongodb）创建要存储的User实体，包含属性：id、username、age1234567891011121314151617public class User { @Id private Long id; private String username; private Integer age; public User(Long id, String username, Integer age) { this.id = id; this.username = username; this.age = age; } // 省略getter和setter}实现User的数据访问对象：UserRepository12345public interface UserRepository extends MongoRepository&lt;User, Long&gt; { User findByUsername(String username);}在单元测试中调用12345678910111213141516171819202122232425262728293031323334@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(Application.class)public class ApplicationTests { @Autowired private UserRepository userRepository; @Before public void setUp() { userRepository.deleteAll(); } @Test public void test() throws Exception { // 创建三个User，并验证User总数 userRepository.save(new User(1L, &quot;didi&quot;, 30)); userRepository.save(new User(2L, &quot;mama&quot;, 40)); userRepository.save(new User(3L, &quot;kaka&quot;, 50)); Assert.assertEquals(3, userRepository.findAll().size()); // 删除一个User，再验证User总数 User u = userRepository.findOne(1L); userRepository.delete(u); Assert.assertEquals(2, userRepository.findAll().size()); // 删除一个User，再验证User总数 u = userRepository.findByUsername(&quot;mama&quot;); userRepository.delete(u); Assert.assertEquals(1, userRepository.findAll().size()); }}参数配置通过上面的例子，我们可以轻而易举的对MongoDB进行访问，但是实战中，应用服务器与MongoDB通常不会部署于同一台设备之上，这样就无法使用自动化的本地配置来进行使用。这个时候，我们也可以方便的配置来完成支持，只需要在application.properties中加入mongodb服务端的相关配置，具体示例如下：1spring.data.mongodb.uri=mongodb://name:pass@localhost:27017/test在尝试此配置时，记得在mongo中对test库创建具备读写权限的用户（用户名为name，密码为pass），不同版本的用户创建语句不同，注意查看文档做好准备工作若使用mongodb 2.x，也可以通过如下参数配置，该方式不支持mongodb 3.x。1spring.data.mongodb.host=localhost spring.data.mongodb.port=27017代码示例本文的相关例子可以查看下面仓库中的chapter3-2-6目录：Github：https://github.com/WuliGitH/SpringBoot-Learning-1文章转自 “程序猿DD” 博客 ,","link":"/2019/03/1553430906000/"},{"title":"Spring Boot多数据源配置与使用","text":"之前在介绍使用JdbcTemplate和Spring-data-jpa时，都使用了单数据源。在单数据源的情况下，Spring Boot的配置非常简单，只需要在application.properties文件中配置连接参数即可。但是往往随着业务量发展，我们通常会进行数据库拆分或是引入其他数据库，从而我们需要配置多个数据源，下面基于之前的JdbcTemplate和Spring-data-jpa例子分别介绍两种多数据源的配置方式。多数据源配置创建一个Spring配置类，定义两个DataSource用来读取application.properties中的不同配置。如下例子中，主数据源配置为spring.datasource.primary开头的配置，第二数据源配置为spring.datasource.secondary开头的配置。12345678910111213141516171819@Configurationpublic class DataSourceConfig { @Bean(name = &quot;primaryDataSource&quot;) @Qualifier(&quot;primaryDataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.datasource.primary&quot;) public DataSource primaryDataSource() { return DataSourceBuilder.create().build(); } @Bean(name = &quot;secondaryDataSource&quot;) @Qualifier(&quot;secondaryDataSource&quot;) @Primary @ConfigurationProperties(prefix=&quot;spring.datasource.secondary&quot;) public DataSource secondaryDataSource() { return DataSourceBuilder.create().build(); }}对应的application.properties配置如下：123456789spring.datasource.primary.url=jdbc:mysql://localhost:3306/test1spring.datasource.primary.username=rootspring.datasource.primary.password=rootspring.datasource.primary.driver-class-name=com.mysql.jdbc.Driverspring.datasource.secondary.url=jdbc:mysql://localhost:3306/test2spring.datasource.secondary.username=rootspring.datasource.secondary.password=rootspring.datasource.secondary.driver-class-name=com.mysql.jdbc.DriverJdbcTemplate支持对JdbcTemplate的支持比较简单，只需要为其注入对应的datasource即可，如下例子，在创建JdbcTemplate的时候分别注入名为primaryDataSource和secondaryDataSource的数据源来区分不同的JdbcTemplate。1234567891011@Bean(name = &quot;primaryJdbcTemplate&quot;)public JdbcTemplate primaryJdbcTemplate( @Qualifier(&quot;primaryDataSource&quot;) DataSource dataSource) { return new JdbcTemplate(dataSource);}@Bean(name = &quot;secondaryJdbcTemplate&quot;)public JdbcTemplate secondaryJdbcTemplate( @Qualifier(&quot;secondaryDataSource&quot;) DataSource dataSource) { return new JdbcTemplate(dataSource);}接下来通过测试用例来演示如何使用这两个针对不同数据源的JdbcTemplate。1234567891011121314151617181920212223242526272829303132333435363738@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(Application.class)public class ApplicationTests { @Autowired @Qualifier(&quot;primaryJdbcTemplate&quot;) protected JdbcTemplate jdbcTemplate1; @Autowired @Qualifier(&quot;secondaryJdbcTemplate&quot;) protected JdbcTemplate jdbcTemplate2; @Before public void setUp() { jdbcTemplate1.update(&quot;DELETE FROM USER &quot;); jdbcTemplate2.update(&quot;DELETE FROM USER &quot;); } @Test public void test() throws Exception { // 往第一个数据源中插入两条数据 jdbcTemplate1.update(&quot;insert into user(id,name,age) values(?, ?, ?)&quot;, 1, &quot;aaa&quot;, 20); jdbcTemplate1.update(&quot;insert into user(id,name,age) values(?, ?, ?)&quot;, 2, &quot;bbb&quot;, 30); // 往第二个数据源中插入一条数据，若插入的是第一个数据源，则会主键冲突报错 jdbcTemplate2.update(&quot;insert into user(id,name,age) values(?, ?, ?)&quot;, 1, &quot;aaa&quot;, 20); // 查一下第一个数据源中是否有两条数据，验证插入是否成功 Assert.assertEquals(&quot;2&quot;, jdbcTemplate1.queryForObject(&quot;select count(1) from user&quot;, String.class)); // 查一下第一个数据源中是否有两条数据，验证插入是否成功 Assert.assertEquals(&quot;1&quot;, jdbcTemplate2.queryForObject(&quot;select count(1) from user&quot;, String.class)); }}代码示例可以查看下面仓库中的chapter3-2-3目录：Github：https://github.com/WuliGitH/SpringBoot-Learning-1如果您觉得本文不错，欢迎Star支持，您的关注是我坚持的动力！Spring-data-jpa支持对于数据源的配置可以沿用上例中DataSourceConfig的实现。新增对第一数据源的JPA配置，注意两处注释的地方，用于指定数据源对应的Entity实体和Repository定义位置，用@Primary区分主数据源。123456789101112131415161718192021222324252627282930313233343536373839404142@Configuration@EnableTransactionManagement@EnableJpaRepositories( entityManagerFactoryRef=&quot;entityManagerFactoryPrimary&quot;, transactionManagerRef=&quot;transactionManagerPrimary&quot;, basePackages= { &quot;com.didispace.domain.p&quot; }) //设置Repository所在位置public class PrimaryConfig { @Autowired @Qualifier(&quot;primaryDataSource&quot;) private DataSource primaryDataSource; @Primary @Bean(name = &quot;entityManagerPrimary&quot;) public EntityManager entityManager(EntityManagerFactoryBuilder builder) { return entityManagerFactoryPrimary(builder).getObject().createEntityManager(); } @Primary @Bean(name = &quot;entityManagerFactoryPrimary&quot;) public LocalContainerEntityManagerFactoryBean entityManagerFactoryPrimary (EntityManagerFactoryBuilder builder) { return builder .dataSource(primaryDataSource) .properties(getVendorProperties(primaryDataSource)) .packages(&quot;com.didispace.domain.p&quot;) //设置实体类所在位置 .persistenceUnit(&quot;primaryPersistenceUnit&quot;) .build(); } @Autowired private JpaProperties jpaProperties; private Map&lt;String, String&gt; getVendorProperties(DataSource dataSource) { return jpaProperties.getHibernateProperties(dataSource); } @Primary @Bean(name = &quot;transactionManagerPrimary&quot;) public PlatformTransactionManager transactionManagerPrimary(EntityManagerFactoryBuilder builder) { return new JpaTransactionManager(entityManagerFactoryPrimary(builder).getObject()); }}新增对第二数据源的JPA配置，内容与第一数据源类似，具体如下：123456789101112131415161718192021222324252627282930313233343536373839@Configuration@EnableTransactionManagement@EnableJpaRepositories( entityManagerFactoryRef=&quot;entityManagerFactorySecondary&quot;, transactionManagerRef=&quot;transactionManagerSecondary&quot;, basePackages= { &quot;com.didispace.domain.s&quot; }) //设置Repository所在位置public class SecondaryConfig { @Autowired @Qualifier(&quot;secondaryDataSource&quot;) private DataSource secondaryDataSource; @Bean(name = &quot;entityManagerSecondary&quot;) public EntityManager entityManager(EntityManagerFactoryBuilder builder) { return entityManagerFactorySecondary(builder).getObject().createEntityManager(); } @Bean(name = &quot;entityManagerFactorySecondary&quot;) public LocalContainerEntityManagerFactoryBean entityManagerFactorySecondary (EntityManagerFactoryBuilder builder) { return builder .dataSource(secondaryDataSource) .properties(getVendorProperties(secondaryDataSource)) .packages(&quot;com.didispace.domain.s&quot;) //设置实体类所在位置 .persistenceUnit(&quot;secondaryPersistenceUnit&quot;) .build(); } @Autowired private JpaProperties jpaProperties; private Map&lt;String, String&gt; getVendorProperties(DataSource dataSource) { return jpaProperties.getHibernateProperties(dataSource); } @Bean(name = &quot;transactionManagerSecondary&quot;) PlatformTransactionManager transactionManagerSecondary(EntityManagerFactoryBuilder builder) { return new JpaTransactionManager(entityManagerFactorySecondary(builder).getObject()); }}完成了以上配置之后，主数据源的实体和数据访问对象位于：com.didispace.domain.p，次数据源的实体和数据访问接口位于：com.didispace.domain.s。分别在这两个package下创建各自的实体和数据访问接口主数据源下，创建User实体和对应的Repository接口1234567891011121314151617181920212223242526@Entitypublic class User { @Id @GeneratedValue private Long id; @Column(nullable = false) private String name; @Column(nullable = false) private Integer age; public User(){} public User(String name, Integer age) { this.name = name; this.age = age; } // 省略getter、setter}public interface UserRepository extends JpaRepository&lt;User, Long&gt; {}从数据源下，创建Message实体和对应的Repository接口1234567891011121314151617181920212223242526@Entitypublic class Message { @Id @GeneratedValue private Long id; @Column(nullable = false) private String name; @Column(nullable = false) private String content; public Message(){} public Message(String name, String content) { this.name = name; this.content = content; } // 省略getter、setter}public interface MessageRepository extends JpaRepository&lt;Message, Long&gt; {}接下来通过测试用例来验证使用这两个针对不同数据源的配置进行数据操作。1234567891011121314151617181920212223242526272829@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(Application.class)public class ApplicationTests { @Autowired private UserRepository userRepository; @Autowired private MessageRepository messageRepository; @Test public void test() throws Exception { userRepository.save(new User(&quot;aaa&quot;, 10)); userRepository.save(new User(&quot;bbb&quot;, 20)); userRepository.save(new User(&quot;ccc&quot;, 30)); userRepository.save(new User(&quot;ddd&quot;, 40)); userRepository.save(new User(&quot;eee&quot;, 50)); Assert.assertEquals(5, userRepository.findAll().size()); messageRepository.save(new Message(&quot;o1&quot;, &quot;aaaaaaaaaa&quot;)); messageRepository.save(new Message(&quot;o2&quot;, &quot;bbbbbbbbbb&quot;)); messageRepository.save(new Message(&quot;o3&quot;, &quot;cccccccccc&quot;)); Assert.assertEquals(3, messageRepository.findAll().size()); }}代码示例可以查看下面仓库中的chapter3-2-4目录：Github：https://github.com/WuliGitH/SpringBoot-Learning-1文章转自 “程序猿DD” 博客 ,","link":"/2019/03/1551510000000/"},{"title":"Spring Boot中使用Redis数据库","text":"Spring Boot中除了对常用的关系型数据库提供了优秀的自动化支持之外，对于很多NoSQL数据库一样提供了自动化配置的支持，包括：Redis, MongoDB, Elasticsearch, Solr和Cassandra。使用RedisRedis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库。Redis官网Redis中文社区引入依赖Spring Boot提供的数据访问框架Spring Data Redis基于Jedis。可以通过引入spring-boot-starter-redis来配置依赖关系。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt;&lt;/dependency&gt;参数配置按照惯例在application.properties中加入Redis服务端的相关配置，具体说明如下：12345678910111213141516171819# REDIS (RedisProperties)# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=localhost# Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0其中spring.redis.database的配置通常使用0即可，Redis在配置的时候可以设置数据库数量，默认为16，可以理解为数据库的schema测试访问通过编写测试用例，举例说明如何访问Redis。1234567891011121314151617@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(Application.class)public class ApplicationTests { @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void test() throws Exception { // 保存字符串 stringRedisTemplate.opsForValue().set(&quot;aaa&quot;, &quot;111&quot;); Assert.assertEquals(&quot;111&quot;, stringRedisTemplate.opsForValue().get(&quot;aaa&quot;)); }}通过上面这段极为简单的测试案例演示了如何通过自动配置的StringRedisTemplate对象进行Redis的读写操作，该对象从命名中就可注意到支持的是String类型。如果有使用过spring-data-redis的开发者一定熟悉RedisTemplate&lt;K, V&gt;接口，StringRedisTemplate就相当于RedisTemplate&lt;String, String&gt;的实现。除了String类型，实战中我们还经常会在Redis中存储对象，这时候我们就会想是否可以使用类似RedisTemplate&lt;String, User&gt;来初始化并进行操作。但是Spring Boot并不支持直接使用，需要我们自己实现RedisSerializer&lt;T&gt;接口来对传入对象进行序列化和反序列化，下面我们通过一个实例来完成对象的读写操作。创建要存储的对象：User123456789101112131415public class User implements Serializable { private static final long serialVersionUID = -1L; private String username; private Integer age; public User(String username, Integer age) { this.username = username; this.age = age; } // 省略getter和setter}实现对象的序列化接口1234567891011121314151617181920212223242526272829303132333435public class RedisObjectSerializer implements RedisSerializer&lt;Object&gt; { private Converter&lt;Object, byte[]&gt; serializer = new SerializingConverter(); private Converter&lt;byte[], Object&gt; deserializer = new DeserializingConverter(); static final byte[] EMPTY_ARRAY = new byte[0]; public Object deserialize(byte[] bytes) { if (isEmpty(bytes)) { return null; } try { return deserializer.convert(bytes); } catch (Exception ex) { throw new SerializationException(&quot;Cannot deserialize&quot;, ex); } } public byte[] serialize(Object object) { if (object == null) { return EMPTY_ARRAY; } try { return serializer.convert(object); } catch (Exception ex) { return EMPTY_ARRAY; } } private boolean isEmpty(byte[] data) { return (data == null || data.length == 0); }}配置针对User的RedisTemplate实例12345678910111213141516171819@Configurationpublic class RedisConfig { @Bean JedisConnectionFactory jedisConnectionFactory() { return new JedisConnectionFactory(); } @Bean public RedisTemplate&lt;String, User&gt; redisTemplate(RedisConnectionFactory factory) { RedisTemplate&lt;String, User&gt; template = new RedisTemplate&lt;String, User&gt;(); template.setConnectionFactory(jedisConnectionFactory()); template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(new RedisObjectSerializer()); return template; }}完成了配置工作后，编写测试用例实验效果123456789101112131415161718192021222324252627@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(Application.class)public class ApplicationTests { @Autowired private RedisTemplate&lt;String, User&gt; redisTemplate; @Test public void test() throws Exception { // 保存对象 User user = new User(&quot;超人&quot;, 20); redisTemplate.opsForValue().set(user.getUsername(), user); user = new User(&quot;蝙蝠侠&quot;, 30); redisTemplate.opsForValue().set(user.getUsername(), user); user = new User(&quot;蜘蛛侠&quot;, 40); redisTemplate.opsForValue().set(user.getUsername(), user); Assert.assertEquals(20, redisTemplate.opsForValue().get(&quot;超人&quot;).getAge().longValue()); Assert.assertEquals(30, redisTemplate.opsForValue().get(&quot;蝙蝠侠&quot;).getAge().longValue()); Assert.assertEquals(40, redisTemplate.opsForValue().get(&quot;蜘蛛侠&quot;).getAge().longValue()); }}当然spring-data-redis中提供的数据操作远不止这些，本文仅作为在Spring Boot中使用redis时的配置参考，更多对于redis的操作使用，请参考Spring-data-redis Reference。文章转自 “程序猿DD” 博客 .","link":"/2019/02/1551337200000/"},{"title":"Spring Boot日志管理","text":"Spring Boot在所有内部日志中使用Commons Logging，但是默认配置也提供了对常用日志的支持，如：Java Util Logging，Log4J, Log4J2和Logback。每种Logger都可以通过配置使用控制台或者文件输出日志内容。格式化日志默认的日志输出如下：12016-04-13 08:23:50.120 INFO 37397 --- [ main] org.hibernate.Version : HHH000412: Hibernate Core {4.3.11.Final}输出内容元素具体如下：时间日期 — 精确到毫秒日志级别 — ERROR, WARN, INFO, DEBUG or TRACE进程ID分隔符 — --- 标识实际日志的开始线程名 — 方括号括起来（可能会截断控制台输出）Logger名 — 通常使用源代码的类名日志内容控制台输出在Spring Boot中默认配置了ERROR、WARN和INFO级别的日志输出到控制台。我们可以通过两种方式切换至DEBUG级别：在运行命令后加入--debug标志，如：$ java -jar myapp.jar --debug在application.properties中配置debug=true，该属性置为true的时候，核心Logger（包含嵌入式容器、hibernate、spring）会输出更多内容，但是你自己应用的日志并不会输出为DEBUG级别。多彩输出如果你的终端支持ANSI，设置彩色输出会让日志更具可读性。通过在application.properties中设置spring.output.ansi.enabled参数来支持。NEVER：禁用ANSI-colored输出（默认项）DETECT：会检查终端是否支持ANSI，是的话就采用彩色输出（推荐项）ALWAYS：总是使用ANSI-colored格式输出，若终端不支持的时候，会有很多干扰信息，不推荐使用文件输出Spring Boot默认配置只会输出到控制台，并不会记录到文件中，但是我们通常生产环境使用时都需要以文件方式记录。若要增加文件输出，需要在application.properties中配置logging.file或logging.path属性。logging.file，设置文件，可以是绝对路径，也可以是相对路径。如：logging.file=my.loglogging.path，设置目录，会在该目录下创建spring.log文件，并写入日志内容，如：logging.path=/var/log日志文件会在10Mb大小的时候被截断，产生新的日志文件，默认级别为：ERROR、WARN、INFO级别控制在Spring Boot中只需要在application.properties中进行配置完成日志记录的级别控制。配置格式：logging.level.*=LEVELlogging.level：日志级别控制前缀，*为包名或Logger名LEVEL：选项TRACE, DEBUG, INFO, WARN, ERROR, FATAL, OFF举例：logging.level.com.didispace=DEBUG：com.didispace包下所有class以DEBUG级别输出logging.level.root=WARN：root日志以WARN级别输出自定义日志配置由于日志服务一般都在ApplicationContext创建前就初始化了，它并不是必须通过Spring的配置文件控制。因此通过系统属性和传统的Spring Boot外部配置文件依然可以很好的支持日志控制和管理。根据不同的日志系统，你可以按如下规则组织配置文件名，就能被正确加载：Logback：logback-spring.xml, logback-spring.groovy, logback.xml, logback.groovyLog4j：log4j-spring.properties, log4j-spring.xml, log4j.properties, log4j.xmlLog4j2：log4j2-spring.xml, log4j2.xmlJDK (Java Util Logging)：logging.propertiesSpring Boot官方推荐优先使用带有-spring的文件名作为你的日志配置（如使用logback-spring.xml，而不是logback.xml）自定义输出格式在Spring Boot中可以通过在application.properties配置如下参数控制输出格式：logging.pattern.console：定义输出到控制台的样式（不支持JDK Logger）logging.pattern.file：定义输出到文件的样式（不支持JDK Logger）文章转自 “程序猿DD” 博客 .","link":"/2019/02/1551250800000/"},{"title":"Spring Boot中使用Spring-data-jpa让数据访问更简单、更优雅","text":"在上一篇 Spring中使用JdbcTemplate访问数据库 中介绍了一种基本的数据访问方式，结合 构建RESTful API 和 使用Thymeleaf模板引擎渲染Web视图 的内容就已经可以完成App服务端和Web站点的开发任务了。然而，在实际开发过程中，对数据库的操作无非就“增删改查”。就最为普遍的单表操作而言，除了表和字段不同外，语句都是类似的，开发人员需要写大量类似而枯燥的语句来完成业务逻辑。为了解决这些大量枯燥的数据操作语句，我们第一个想到的是使用ORM框架，比如：Hibernate。通过整合Hibernate之后，我们以操作Java实体的方式最终将数据改变映射到数据库表中。为了解决抽象各个Java实体基本的“增删改查”操作，我们通常会以泛型的方式封装一个模板Dao来进行抽象简化，但是这样依然不是很方便，我们需要针对每个实体编写一个继承自泛型模板Dao的接口，再编写该接口的实现。虽然一些基础的数据访问已经可以得到很好的复用，但是在代码结构上针对每个实体都会有一堆Dao的接口和实现。由于模板Dao的实现，使得这些具体实体的Dao层已经变的非常“薄”，有一些具体实体的Dao实现可能完全就是对模板Dao的简单代理，并且往往这样的实现类可能会出现在很多实体上。Spring-data-jpa的出现正可以让这样一个已经很“薄”的数据访问层变成只是一层接口的编写方式。比如，下面的例子：12345678public interface UserRepository extends JpaRepository&lt;User, Long&gt; { User findByName(String name); @Query(&quot;from User u where u.name=:name&quot;) User findUser(@Param(&quot;name&quot;) String name);}我们只需要通过编写一个继承自JpaRepository的接口就能完成数据访问，下面以一个具体实例来体验Spring-data-jpa给我们带来的强大功能。使用示例由于Spring-data-jpa依赖于Hibernate。如果您对Hibernate有一定了解，下面内容可以毫不费力的看懂并上手使用Spring-data-jpa。如果您还是Hibernate新手，您可以先按如下方式入门，再建议回头学习一下Hibernate以帮助这部分的理解和进一步使用。工程配置在pom.xml中添加相关依赖，加入以下内容：1234&lt;dependency &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;在application.properties中配置：数据库连接信息（如使用嵌入式数据库则不需要）、自动创建表结构的设置，例如使用mysql的情况如下：123456spring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=rootspring.datasource.password=rootspring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.jpa.properties.hibernate.ddl-auto=create-dropspring.jpa.properties.hibernate.ddl-auto是hibernate的配置属性，其主要作用是：自动创建、更新、验证数据库表结构。该参数的几种配置如下：create：每次加载hibernate时都会删除上一次的生成的表，然后根据你的model类再重新来生成新表，哪怕两次没有任何改变也要这样执行，这就是导致数据库表数据丢失的一个重要原因。create-drop：每次加载hibernate时根据model类生成表，但是sessionFactory一关闭,表就自动删除。update：最常用的属性，第一次加载hibernate时根据model类会自动建立起表的结构（前提是先建立好数据库），以后加载hibernate时根据model类自动更新表结构，即使表结构改变了但表中的行仍然存在不会删除以前的行。要注意的是当部署到服务器后，表结构是不会被马上建立起来的，是要等应用第一次运行起来后才会。validate：每次加载hibernate时，验证创建数据库表结构，只会和数据库中的表进行比较，不会创建新表，但是会插入新值。至此已经完成基础配置，如果您有在Spring下整合使用过它的话，相信你已经感受到Spring Boot的便利之处：JPA的传统配置在persistence.xml文件中，但是这里我们不需要。创建实体创建一个User实体，包含id（主键）、name（姓名）、age（年龄）属性，通过ORM框架其会被映射到数据库表中，由于配置了spring.jpa.properties.hibernate.ddl-auto，在应用启动的时候框架会自动去数据库中创建对应的表。123456789101112131415161718@Entitypublic class User { @Id @GeneratedValue private Long id; @Column(nullable = false) private String name; @Column(nullable = false) private Integer age; // 省略构造函数 // 省略getter和setter}创建数据访问接口下面针对User实体创建对应的Repository接口实现对该实体的数据访问，如下代码：12345678910public interface UserRepository extends JpaRepository&lt;User, Long&gt; { User findByName(String name); User findByNameAndAge(String name, Integer age); @Query(&quot;from User u where u.name=:name&quot;) User findUser(@Param(&quot;name&quot;) String name);}在Spring-data-jpa中，只需要编写类似上面这样的接口就可实现数据访问。不再像我们以往编写了接口时候还需要自己编写接口实现类，直接减少了我们的文件清单。下面对上面的UserRepository做一些解释，该接口继承自JpaRepository，通过查看JpaRepository接口的API文档，可以看到该接口本身已经实现了创建（save）、更新（save）、删除（delete）、查询（findAll、findOne）等基本操作的函数，因此对于这些基础操作的数据访问就不需要开发者再自己定义。在我们实际开发中，JpaRepository接口定义的接口往往还不够或者性能不够优化，我们需要进一步实现更复杂一些的查询或操作。由于本文重点在spring boot中整合spring-data-jpa，在这里先抛砖引玉简单介绍一下spring-data-jpa中让我们兴奋的功能，后续再单独开篇讲一下spring-data-jpa中的常见使用。在上例中，我们可以看到下面两个函数：User findByName(String name)User findByNameAndAge(String name, Integer age)它们分别实现了按name查询User实体和按name和age查询User实体，可以看到我们这里没有任何类SQL语句就完成了两个条件查询方法。这就是Spring-data-jpa的一大特性：通过解析方法名创建查询。除了通过解析方法名来创建查询外，它也提供通过使用@Query 注解来创建查询，您只需要编写JPQL语句，并通过类似“:name”来映射@Param指定的参数，就像例子中的第三个findUser函数一样。Spring-data-jpa的能力远不止本文提到的这些，由于本文主要以整合介绍为主，对于Spring-data-jpa的使用只是介绍了常见的使用方式。诸如@Modifying操作、分页排序、原生SQL支持以及与Spring MVC的结合使用等等内容就不在本文中详细展开，这里先挖个坑，后续再补文章填坑，如您对这些感兴趣可以关注我博客或简书，同样欢迎大家留言交流想法。单元测试在完成了上面的数据访问接口之后，按照惯例就是编写对应的单元测试来验证编写的内容是否正确。这里就不多做介绍，主要通过数据操作和查询来反复验证操作的正确性。123456789101112131415161718192021222324252627282930313233343536373839404142@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(Application.class)public class ApplicationTests { @Autowired private UserRepository userRepository; @Test public void test() throws Exception { // 创建10条记录 userRepository.save(new User(\"AAA\", 10)); userRepository.save(new User(\"BBB\", 20)); userRepository.save(new User(\"CCC\", 30)); userRepository.save(new User(\"DDD\", 40)); userRepository.save(new User(\"EEE\", 50)); userRepository.save(new User(\"FFF\", 60)); userRepository.save(new User(\"GGG\", 70)); userRepository.save(new User(\"HHH\", 80)); userRepository.save(new User(\"III\", 90)); userRepository.save(new User(\"JJJ\", 100)); // 测试findAll, 查询所有记录 Assert.assertEquals(10, userRepository.findAll().size()); // 测试findByName, 查询姓名为FFF的User Assert.assertEquals(60, userRepository.findByName(\"FFF\").getAge().longValue()); // 测试findUser, 查询姓名为FFF的User Assert.assertEquals(60, userRepository.findUser(\"FFF\").getAge().longValue()); // 测试findByNameAndAge, 查询姓名为FFF并且年龄为60的User Assert.assertEquals(\"FFF\", userRepository.findByNameAndAge(\"FFF\", 60).getName()); // 测试删除姓名为AAA的User userRepository.delete(userRepository.findByName(\"AAA\")); // 测试findAll, 查询所有记录, 验证上面的删除是否成功 Assert.assertEquals(9, userRepository.findAll().size()); }}文章转自 “程序猿DD” 博客 .","link":"/2019/02/1551164400000/"},{"title":"Spring Boot中使用JdbcTemplate访问数据库","text":"之前介绍了很多Web层的例子，包括构建RESTful API、使用Thymeleaf模板引擎渲染Web视图，但是这些内容还不足以构建一个动态的应用。通常我们做App也好，做Web应用也好，都需要内容，而内容通常存储于各种类型的数据库，服务端在接收到访问请求之后需要访问数据库获取并处理成展现给用户使用的数据形式。本文介绍在Spring Boot基础下配置数据源和通过JdbcTemplate编写数据访问的示例。数据源配置在我们访问数据库的时候，需要先配置一个数据源，下面分别介绍一下几种不同的数据库配置方式。首先，为了连接数据库需要引入jdbc支持，在pom.xml中引入如下配置：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;嵌入式数据库支持嵌入式数据库通常用于开发和测试环境，不推荐用于生产环境。Spring Boot提供自动配置的嵌入式数据库有H2、HSQL、Derby，你不需要提供任何连接配置就能使用。比如，我们可以在pom.xml中引入如下配置使用HSQL12345&lt;dependency&gt; &lt;groupId&gt;org.hsqldb&lt;/groupId&gt; &lt;artifactId&gt;hsqldb&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;连接生产数据源以MySQL数据库为例，先引入MySQL连接的依赖包，在pom.xml中加入：1234&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;在src/main/resources/application.properties中配置数据源信息1234spring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=rootspring.datasource.password=rootspring.datasource.driver-class-name=com.mysql.jdbc.Driver连接JNDI数据源当你将应用部署于应用服务器上的时候想让数据源由应用服务器管理，那么可以使用如下配置方式引入JNDI数据源。1spring.datasource.jndi-name=java:jboss/datasources/customers使用JdbcTemplate操作数据库Spring的JdbcTemplate是自动配置的，你可以直接使用@Autowired来注入到你自己的bean中来使用。举例：我们在创建User表，包含属性name、age，下面来编写数据访问对象和单元测试用例。定义包含有插入、删除、查询的抽象接口UserService1234567891011121314151617181920212223242526public interface UserService { /** * 新增一个用户 * @param name * @param age */ void create(String name, Integer age); /** * 根据name删除一个用户高 * @param name */ void deleteByName(String name); /** * 获取用户总量 */ Integer getAllUsers(); /** * 删除所有用户 */ void deleteAllUsers();}通过JdbcTemplate实现UserService中定义的数据访问操作1234567891011121314151617181920212223242526@Servicepublic class UserServiceImpl implements UserService { @Autowired private JdbcTemplate jdbcTemplate; @Override public void create(String name, Integer age) { jdbcTemplate.update(&quot;insert into USER(NAME, AGE) values(?, ?)&quot;, name, age); } @Override public void deleteByName(String name) { jdbcTemplate.update(&quot;delete from USER where NAME = ?&quot;, name); } @Override public Integer getAllUsers() { return jdbcTemplate.queryForObject(&quot;select count(1) from USER&quot;, Integer.class); } @Override public void deleteAllUsers() { jdbcTemplate.update(&quot;delete from USER&quot;); }}创建对UserService的单元测试用例，通过创建、删除和查询来验证数据库操作的正确性。1234567891011121314151617181920212223242526272829303132333435@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(Application.class)public class ApplicationTests { @Autowired private UserService userSerivce; @Before public void setUp() { // 准备，清空user表 userSerivce.deleteAllUsers(); } @Test public void test() throws Exception { // 插入5个用户 userSerivce.create(&quot;a&quot;, 1); userSerivce.create(&quot;b&quot;, 2); userSerivce.create(&quot;c&quot;, 3); userSerivce.create(&quot;d&quot;, 4); userSerivce.create(&quot;e&quot;, 5); // 查数据库，应该有5个用户 Assert.assertEquals(5, userSerivce.getAllUsers().intValue()); // 删除两个用户 userSerivce.deleteByName(&quot;a&quot;); userSerivce.deleteByName(&quot;e&quot;); // 查数据库，应该有5个用户 Assert.assertEquals(3, userSerivce.getAllUsers().intValue()); }}上面介绍的JdbcTemplate只是最基本的几个操作，更多其他数据访问操作的使用请参考：JdbcTemplate API通过上面这个简单的例子，我们可以看到在Spring Boot下访问数据库的配置依然秉承了框架的初衷：简单。我们只需要在pom.xml中加入数据库依赖，再到application.properties中配置连接信息，不需要像Spring应用中创建JdbcTemplate的Bean，就可以直接在自己的对象中注入使用文章转自 “程序猿DD” 博客 .","link":"/2019/02/1551078000000/"},{"title":"Spring Boot中使用Swagger2构建强大的RESTful API文档","text":"由于Spring Boot能够快速开发、便捷部署等特性，相信有很大一部分Spring Boot的用户会用来构建RESTful API。而我们构建RESTful API的目的通常都是由于多终端的原因，这些终端会共用很多底层业务逻辑，因此我们会抽象出这样一层来同时服务于多个移动端或者Web前端。这样一来，我们的RESTful API就有可能要面对多个开发人员或多个开发团队：IOS开发、Android开发或是Web开发等。为了减少与其他团队平时开发期间的频繁沟通成本，传统做法我们会创建一份RESTful API文档来记录所有接口细节，然而这样的做法有以下几个问题：由于接口众多，并且细节复杂（需要考虑不同的HTTP请求类型、HTTP头部信息、HTTP请求内容等），高质量地创建这份文档本身就是件非常吃力的事，下游的抱怨声不绝于耳。随着时间推移，不断修改接口实现的时候都必须同步修改接口文档，而文档与代码又处于两个不同的媒介，除非有严格的管理机制，不然很容易导致不一致现象。为了解决上面这样的问题，本文将介绍RESTful API的重磅好伙伴Swagger2，它可以轻松的整合到Spring Boot中，并与Spring MVC程序配合组织出强大RESTful API文档。它既可以减少我们创建文档的工作量，同时说明内容又整合入实现代码中，让维护文档和修改代码整合为一体，可以让我们在修改代码逻辑的同时方便的修改文档说明。另外Swagger2也提供了强大的页面测试功能来调试每个RESTful API。具体效果如下图所示：下面来具体介绍，如果在Spring Boot中使用Swagger2。首先，我们需要一个Spring Boot实现的RESTful API工程，若您没有做过这类内容，建议先阅读Spring Boot构建一个较为复杂的RESTful APIs和单元测试。下面的内容我们会以教程样例中的Chapter3-1-1进行下面的实验（Chapter3-1-5是我们的结果工程，亦可参考）。添加Swagger2依赖在pom.xml中加入Swagger2的依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;创建Swagger2配置类在Application.java同级创建Swagger2的配置类Swagger2。1234567891011121314151617181920212223@Configurationpublic class Swagger2 { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(&quot;cn.rickyxd.web&quot;)) .paths(PathSelectors.any()) .build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(&quot;Spring Boot中使用Swagger2构建RESTful APIs&quot;) .description(&quot;更多Spring Boot相关文章请关注：https://img.jacian.com/&lt;br&gt;&lt;br&gt;&lt;h3&gt;Create By Ricky Liu&lt;/h3&gt;&quot;) //.termsOfServiceUrl(&quot;https://img.jacian.com/&quot;) //.contact(&quot;Ricky Liu&quot;) .version(&quot;1.0&quot;) .build(); }}如上代码所示，通过@Configuration注解，让Spring来加载该类配置。再通过在启动类上添加@EnableSwagger2注解来启用Swagger2。再通过createRestApi函数创建Docket的Bean之后，apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中）。select()函数返回一个ApiSelectorBuilder实例用来控制哪些接口暴露给Swagger来展现，本例采用指定扫描的包路径来定义，Swagger会扫描该包下所有Controller定义的API，并产生文档内容（除了被@ApiIgnore指定的请求）。添加文档内容在完成了上述配置后，其实已经可以生产文档内容，但是这样的文档主要针对请求本身，而描述主要来源于函数等命名产生，对用户并不友好，我们通常需要自己增加一些说明来丰富文档内容。如下所示，我们通过@ApiOperation注解来给API增加说明、通过@ApiImplicitParams、@ApiImplicitParam注解来给参数增加说明。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283@RestController// 配置使以下映射都在 /users 下@RequestMapping(&quot;/users&quot;)public class UserController { /** * 创建线程安全的Map */ private static Map&lt;Long, User&gt; users = Collections.synchronizedMap(new HashMap&lt;Long, User&gt;()); /** * 处理 &quot;/users/&quot; 的GET请求,用来获取用户列表 * 还可以通过 @RequestParam 从页面中传递参数进行查询条件或者分页信息的传递 * @return 用户列表 */ @ApiOperation(value=&quot;获取用户列表&quot;, notes=&quot;&quot;) @GetMapping(&quot;/&quot;) public List&lt;User&gt; getUserList() { return new ArrayList&lt;User&gt;(users.values()); } /** * 处理 &quot;/users/&quot; 的 POST 请求 , 用来创建 User * 还可以通过@RequestParam从页面中传递参数 * @param user 用户信息 * @return 创建 user 的成功与否 */ @ApiOperation(value=&quot;创建用户&quot;, notes=&quot;根据User对象创建用户&quot;) @ApiImplicitParam(name = &quot;user&quot;, value = &quot;用户详细实体user&quot;, required = true, dataType = &quot;User&quot;) @PostMapping(&quot;/&quot;) public String postUser(@RequestBody User user) { users.put(user.getId(), user); return &quot;success&quot;; } /** * 处理&quot;/users/{id}&quot;的GET请求，用来获取url中id值的User信息 * url中的id可通过@PathVariable绑定到函数的参数中 * @param id 用户ID * @return 用户信息 */ @ApiOperation(value=&quot;获取用户详细信息&quot;, notes=&quot;根据url的id来获取用户详细信息&quot;) @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true, dataType = &quot;Long&quot;) @GetMapping(&quot;/{id}&quot;) public User getUser(@PathVariable Long id) { // 处理&quot;/users/{id}&quot;的GET请求，用来获取url中id值的User信息 // url中的id可通过@PathVariable绑定到函数的参数中 return users.get(id); } /** * 处理&quot;/users/{id}&quot;的PUT请求，用来更新User信息 * @param id 用户ID * @param user 更新后的用户信息 * @return 是否更新成功 */ @ApiOperation(value=&quot;更新用户详细信息&quot;, notes=&quot;根据url的id来指定更新对象，并根据传过来的user信息来更新用户详细信息&quot;) @ApiImplicitParams({ @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true, dataType = &quot;Long&quot;), @ApiImplicitParam(name = &quot;user&quot;, value = &quot;用户详细实体user&quot;, required = true, dataType = &quot;User&quot;) }) @PutMapping(&quot;/{id}&quot;) public String putUser(@PathVariable Long id, @RequestBody User user) { User u = users.get(id); u.setName(user.getName()); u.setAge(user.getAge()); users.put(id, u); return &quot;success&quot;; } /** * 处理&quot;/users/{id}&quot;的DELETE请求，用来删除User * @param id 用户ID * @return 是否删除成功 */ @ApiOperation(value=&quot;删除用户&quot;, notes=&quot;根据url的id来指定删除对象&quot;) @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true, dataType = &quot;Long&quot;) @DeleteMapping(&quot;/{id}&quot;) public String deleteUser(@PathVariable Long id) { users.remove(id); return &quot;success&quot;; }}完成上述代码添加上，启动Spring Boot程序，访问：https://localhost:8080/swagger-ui.html。就能看到前文所展示的RESTful API的页面。我们可以再点开具体的API请求，以POST类型的/users请求为例，可找到上述代码中我们配置的Notes信息以及参数user的描述信息，单击Try it out，如下图所示。输入属性对应的值点击Execute即代表发送相应请求API文档访问与调试在上图请求的页面中，我们看到user的Value是个输入框？是的，Swagger除了查看接口功能外，还提供了调试测试功能，我们可以点击上图中右侧的Model Schema（黄色区域：它指明了User的数据结构），此时Value中就有了user对象的模板，我们只需要稍适修改，点击下方“Try it out！”按钮，即可完成了一次请求调用！此时，你也可以通过几个GET请求来验证之前的POST请求是否正确。相比为这些接口编写文档的工作，我们增加的配置内容是非常少而且精简的，对于原有代码的侵入也在忍受范围之内。因此，在构建RESTful API的同时，加入swagger来对API文档进行管理，是个不错的选择。参考信息Swagger官方网站https://swagger.io/)文章转自 “程序猿DD” 博客 .","link":"/2019/02/1550991600000/"},{"title":"Spring Boot构建RESTful API与单元测试","text":"@Controller：修饰class，用来创建处理http请求的对象@RestController：Spring4之后加入的注解，原来在@Controller中返回json需要@ResponseBody来配合，如果直接用@RestController替代@Controller就不需要再配置@ResponseBody，默认返回json格式。@RequestMapping：配置url映射下面我们尝试使用Spring MVC来实现一组对User对象操作的RESTful API，配合注释详细说明在Spring MVC中如何映射HTTP请求、如何传参、如何编写单元测试。RESTful API具体设计如下：User实体定义：123456789public class User { private Long id; private String name; private Integer age; // 省略setter和getter}实现对User对象的操作接口1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@RestController// 配置使以下映射都在 /users 下@RequestMapping(\"/users\")public class UserController { /** * 创建线程安全的Map */ private static Map&lt;Long, User&gt; users = Collections.synchronizedMap(new HashMap&lt;Long, User&gt;()); /** * 处理 \"/users/\" 的GET请求,用来获取用户列表 * 还可以通过 @RequestParam 从页面中传递参数进行查询条件或者分页信息的传递 * @return 用户列表 */ @GetMapping(\"/\") public List&lt;User&gt; getUserList() { return new ArrayList&lt;User&gt;(users.values()); } /** * 处理 \"/users/\" 的 POST 请求 , 用来创建 User * 还可以通过@RequestParam从页面中传递参数 * @param user 用户信息 * @return 创建 user 的成功与否 */ @PostMapping(\"/\") public String postUser(@RequestBody User user) { users.put(user.getId(), user); return \"success\"; } /** * 处理\"/users/{id}\"的GET请求，用来获取url中id值的User信息 * url中的id可通过@PathVariable绑定到函数的参数中 * @param id 用户ID * @return 用户信息 */ @GetMapping(\"/{id}\") public User getUser(@PathVariable Long id) { // 处理\"/users/{id}\"的GET请求，用来获取url中id值的User信息 // url中的id可通过@PathVariable绑定到函数的参数中 return users.get(id); } /** * 处理\"/users/{id}\"的PUT请求，用来更新User信息 * @param id 用户ID * @param user 更新后的用户信息 * @return 是否更新成功 */ @PutMapping(\"/{id}\") public String putUser(@PathVariable Long id, @ModelAttribute User user) { User u = users.get(id); u.setName(user.getName()); u.setAge(user.getAge()); users.put(id, u); return \"success\"; } /** * 处理\"/users/{id}\"的DELETE请求，用来删除User * @param id 用户ID * @return 是否删除成功 */ @DeleteMapping(\"/{id}\") public String deleteUser(@PathVariable Long id) { users.remove(id); return \"success\"; }}下面针对该Controller编写测试用例验证正确性，具体如下。当然也可以通过浏览器插件等进行请求提交验证。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = MockServletContext.class)@WebAppConfigurationpublic class ApplicationTests { private MockMvc mvc; @Before public void setUp() throws Exception { mvc = MockMvcBuilders.standaloneSetup(new UserController()).build(); } @Test public void testUserController() throws Exception { // 测试UserController RequestBuilder request = null; // 1、get查一下user列表，应该为空 request = get(\"/users/\"); mvc.perform(request) .andExpect(status().isOk()) .andExpect(content().string(equalTo(\"[]\"))); // 2、post提交一个user request = post(\"/users/\") .param(\"id\", \"1\") .param(\"name\", \"测试大师\") .param(\"age\", \"20\"); mvc.perform(request) .andExpect(content().string(equalTo(\"success\"))); // 3、get获取user列表，应该有刚才插入的数据 request = get(\"/users/\"); mvc.perform(request) .andExpect(status().isOk()) .andExpect(content().string(equalTo(\"[{\\\"id\\\":1,\\\"name\\\":\\\"测试大师\\\",\\\"age\\\":20}]\"))); // 4、put修改id为1的user request = put(\"/users/1\") .param(\"name\", \"测试终极大师\") .param(\"age\", \"30\"); mvc.perform(request) .andExpect(content().string(equalTo(\"success\"))); // 5、get一个id为1的user request = get(\"/users/1\"); mvc.perform(request) .andExpect(content().string(equalTo(\"{\\\"id\\\":1,\\\"name\\\":\\\"测试终极大师\\\",\\\"age\\\":30}\"))); // 6、del删除id为1的user request = delete(\"/users/1\"); mvc.perform(request) .andExpect(content().string(equalTo(\"success\"))); // 7、get查一下user列表，应该为空 request = get(\"/users/\"); mvc.perform(request) .andExpect(status().isOk()) .andExpect(content().string(equalTo(\"[]\"))); }}至此，我们通过引入web模块（没有做其他的任何配置），就可以轻松利用Spring MVC的功能，以非常简洁的代码完成了对User对象的RESTful API的创建以及单元测试的编写。其中同时介绍了Spring MVC中最为常用的几个核心注解：@Controller,@RestController,RequestMapping以及一些参数绑定的注解：@PathVariable,@ModelAttribute,@RequestParam等。文章转自 “程序猿DD” 博客 .","link":"/2019/02/1550905200000/"},{"title":"Spring Boot开发Web应用","text":"静态资源访问在我们开发Web应用的时候，需要引用大量的js、css、图片等静态资源。默认配置Spring Boot默认提供静态资源目录位置需置于classpath下，目录名需符合如下规则：/static/public/resources/META-INF/resources举例：我们可以在src/main/resources/目录下创建static，在该位置放置一个图片文件。启动程序后，尝试访问https://localhost:8080/D.jpg。如能显示图片，配置成功。渲染Web页面在之前的示例中，我们都是通过@RestController来处理请求，所以返回的内容为json对象。那么如果需要渲染html页面的时候，要如何实现呢？模板引擎在动态HTML实现上Spring Boot依然可以完美胜任，并且提供了多种模板引擎的默认配置支持，所以在推荐的模板引擎下，我们可以很快的上手开发动态网站。Spring Boot提供了默认配置的模板引擎主要有以下几种：ThymeleafFreeMarkerVelocityGroovyMustacheSpring Boot建议使用这些模板引擎，避免使用JSP，若一定要使用JSP将无法实现Spring Boot的多种特性，具体可见后文：支持JSP的配置当你使用上述模板引擎中的任何一个，它们默认的模板配置路径为：src/main/resources/templates。当然也可以修改这个路径，具体如何修改，可在后续各模板引擎的配置属性中查询并修改。ThymeleafThymeleaf是一个XML/XHTML/HTML5模板引擎，可用于Web与非Web环境中的应用开发。它是一个开源的Java库，基于Apache License 2.0许可，由Daniel Fernández创建，该作者还是Java加密库Jasypt的作者。Thymeleaf提供了一个用于整合Spring MVC的可选模块，在应用开发中，你可以使用Thymeleaf来完全代替JSP或其他模板引擎，如Velocity、FreeMarker等。Thymeleaf的主要目标在于提供一种可被浏览器正确显示的、格式良好的模板创建方式，因此也可以用作静态建模。你可以使用它创建经过验证的XML与HTML模板。相对于编写逻辑或代码，开发者只需将标签属性添加到模板中即可。接下来，这些标签属性就会在DOM（文档对象模型）上执行预先制定好的逻辑。示例模板：1234567891011121314&lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th th:text=&quot;#{msgs.headers.name}&quot;&gt;Name&lt;/td&gt; &lt;th th:text=&quot;#{msgs.headers.price}&quot;&gt;Price&lt;/td&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr th:each=&quot;prod : ${allProducts}&quot;&gt; &lt;td th:text=&quot;${prod.name}&quot;&gt;Oranges&lt;/td&gt; &lt;td th:text=&quot;${#numbers.formatDecimal(prod.price,1,2)}&quot;&gt;0.99&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;可以看到Thymeleaf主要以属性的方式加入到html标签中，浏览器在解析html时，当检查到没有的属性时候会忽略，所以Thymeleaf的模板可以通过浏览器直接打开展现，这样非常有利于前后端的分离。在Spring Boot中使用Thymeleaf，只需要引入下面依赖，并在默认的模板路径src/main/resources/templates下编写模板文件即可完成。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;在完成配置之后，举一个简单的例子，在快速入门工程的基础上，举一个简单的示例来通过Thymeleaf渲染一个页面。12345678910111213141516171819202122@Controllerpublic class HelloController { @RequestMapping(&quot;/&quot;) public String index(ModelMap map) { // 加入一个属性，用来在模板中读取 map.addAttribute(&quot;host&quot;, &quot;https://img.jacian.com&quot;); // return模板文件的名称，对应src/main/resources/templates/index.html return &quot;index&quot;; }}&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang=&quot;en&quot;&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1 th:text=&quot;${host}&quot;&gt;Hello World&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;如上页面，直接打开html页面展现Hello World，但是启动程序后，访问https://localhost:8080/，则是展示Controller中host的值：https://img.jacian.com，做到了不破坏HTML自身内容的数据逻辑分离。更多Thymeleaf的页面语法，还请访问Thymeleaf的官方文档查询使用。Thymeleaf的默认参数配置如有需要修改默认配置的时候，只需复制下面要修改的属性到application.properties中，并修改成需要的值，如修改模板文件的扩展名，修改默认的模板路径等。12345678910spring: thymeleaf: cache: true check-template-location: true content-type: text/html enabled: true encoding: UTF-8 mode: HTML5 prefix: classpath:/templates/ suffix: .html支持JSP的配置Spring Boot并不建议使用，但如果一定要使用，可以参考此工程作为脚手架：JSP支持文章转自 “程序猿DD” 博客 .","link":"/2019/02/1550818800000/"},{"title":"SpringBoot快速入门","text":"SpringBoot主要优点为所有Spring开发者更快的入门开箱即用，提供各种默认配置来简化项目配置内嵌式容器简化Web项目没有冗余代码生成和XML配置的要求本文所用工具版本Maven3.6.0JDK 1.8SpringBoot 1.5.19使用Maven构建项目通过 SPRING INITIALIZR 构建项目访问: https://start.spring.io/ ;选择构建工具Maven Project、Spring Boot版本1.5.19以及一些工程基本信息，可参考下图所示 ;点击 Generate Project下载项目压缩包 ;解压项目包 , 并用IDE 以Maven项目导入 , 以 IDEA 为例菜单中选择File–&gt;New–&gt;Project from Existing Sources...选择解压后的项目文件夹，点击OK点击Import project from external model并选择Maven，点击Next到底为止。若你的环境有多个版本的JDK，注意到选择Java SDK的时候请选择Java 7以上的版本项目结构解析通过上面步骤完成了基础项目的创建，如上图所示，Spring Boot的基础结构共三个文件（具体路径根据用户生成项目时填写的Group所有差异）：src/main/java下的程序入口：Learning1Applicationsrc/main/resources下的配置文件：application.propertiessrc/test/下的测试入口：Learning1ApplicationTests生成的Learning1Application和Learning1ApplicationTests类都可以直接运行来启动当前创建的项目，由于目前该项目未配合任何数据访问或Web模块，程序会在加载完Spring之后结束运行。引入Web模块当前的pom.xml内容如下，仅引入了两个模块：spring-boot-starter：核心模块，包括自动配置支持、日志和YAMLspring-boot-starter-test：测试模块，包括JUnit、Hamcrest、Mockito123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;引入Web模块，需添加spring-boot-starter-web模块：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;编写HelloWorld服务创建package命名为cn.rickyxd.web（根据实际情况修改）创建HelloWorldController类，内容如下1234567@RestControllerpublic class HelloWorldController { @RequestMapping(\"/hello\") public String hello() { return \"HelloWorld!\"; }}启动主程序，打开浏览器访问https://localhost:8080/hello，可以看到页面输出Hello World编写单元测试用例打开的src/test/下的测试入口Chapter1ApplicationTests类。下面编写一个简单的单元测试来模拟http请求，具体如下:1234567891011121314151617181920212223@SpringBootTest// 使用Spring Test组件进行单元测试 , 其中SpringRunner继承SpringJUnit4ClassRunner@RunWith(SpringRunner.class)// 测试环境使用，用来表示测试环境使用的ApplicationContext将是WebApplicationContext类型的；value指定web应用的根@WebAppConfiguration// 注入 MockMvc 实例@AutoConfigureMockMvcpublic class Learning1ApplicationTests { private MockMvc mvc; @Before public void setUp() throws Exception { mvc = MockMvcBuilders.standaloneSetup(new HelloWorldController()).build(); } @Test public void contextLoads() throws Exception { mvc.perform(MockMvcRequestBuilders.get(\"/hello\").accept(MediaType.APPLICATION_JSON_UTF8)) .andExpect(status().isOk()) .andExpect(content().string(equalTo(\"Hello World!\"))); }}注意引入下面内容，让status、content、equalTo函数可用123import static org.hamcrest.Matchers.equalTo;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;至此已完成目标，通过Maven构建了一个空白Spring Boot项目，再通过引入web模块实现了一个简单的请求处理。文章转自 “程序猿DD” 博客 .","link":"/2019/02/1550732400000/"},{"title":"Spring 加载多个 properties 文件 报错","text":"1. 问题描述启动web项目时保存 , 该问题出现的原因为 spring 加载 properties 文件时无法找到对应的属性值 ;Caused by : java.lang.IllegalArgumentException: Could not resolve placeholder ‘xxx’ in string value “${xxx}”2. 问题分析提示我无法解析占位符 , 导入 log4j 配置文件之后 , 发现并没有加载到所对应的properties文件 ;这里只是解析了 “redis-config.properties” 但是并没有加载 , 所以导致找不到对应的属性值 ;3. 问题解决及原因查了下资料发现 spring 容器中仅允许且最多只会扫描一个 properties 文件 , 当扫描到 properties 时 , 后边的 properties 文件会被忽略掉 ;解决方案一在每个 context:property-placeholder 中添加 ignore-unresolvable=”true” 属性 ;解决方案二将 properties 所在的文件夹名称改为一致 ;","link":"/2019/02/1550646000000/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"WebSocket","slug":"WebSocket","link":"/tags/WebSocket/"},{"name":"SocketIO","slug":"SocketIO","link":"/tags/SocketIO/"},{"name":"Joda","slug":"Joda","link":"/tags/Joda/"},{"name":"DateTime","slug":"DateTime","link":"/tags/DateTime/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"博客","slug":"博客","link":"/tags/博客/"},{"name":"线程","slug":"线程","link":"/tags/线程/"},{"name":"数据结构","slug":"数据结构","link":"/tags/数据结构/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Kafka","slug":"Kafka","link":"/tags/Kafka/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/tags/Zookeeper/"},{"name":"Shell","slug":"Shell","link":"/tags/Shell/"}],"categories":[{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/categories/SpringBoot/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"WebSocket","slug":"WebSocket","link":"/categories/WebSocket/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"数据结构","slug":"数据结构","link":"/categories/数据结构/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"MySQL","slug":"MySQL","link":"/categories/MySQL/"}]}